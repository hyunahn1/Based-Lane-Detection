#!/usr/bin/env python3
"""
ğŸš— CARLA ìë™ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
=================================

ì‚¬ìš©ë²•:
    python auto_collect.py --duration 10

ì„¤ëª…:
    - CARLA Autopilotìœ¼ë¡œ ìë™ ì£¼í–‰
    - ì´ë¯¸ì§€ + steering/throttle ë™ì‹œ ì €ì¥
    - Object detectionìš© bboxë„ ìë™ ìƒì„±
    - 10ë¶„ ëŒë¦¬ë©´ ~10,000ì¥ ìˆ˜ì§‘

ì‘ì„±: 2026-01-30
"""

import carla
import numpy as np
import cv2
import pandas as pd
import argparse
import time
import os
import json
from pathlib import Path
from datetime import datetime
from queue import Queue, Empty
from collections import deque


class CARLADataCollector:
    """CARLA ìë™ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, output_dir='collected_data', fps=10):
        """
        Args:
            output_dir: ì €ì¥ í´ë”
            fps: ì´ˆë‹¹ ì €ì¥ í”„ë ˆì„ ìˆ˜ (10 = 1ì´ˆì— 10ì¥)
        """
        self.output_dir = Path(output_dir)
        self.fps = fps
        self.frame_interval = 1.0 / fps
        
        # í´ë” ìƒì„±
        self.image_dir = self.output_dir / 'images'
        self.label_dir = self.output_dir / 'labels'
        self.image_dir.mkdir(parents=True, exist_ok=True)
        self.label_dir.mkdir(parents=True, exist_ok=True)
        
        # CARLA ì—°ê²°
        print("ğŸ”Œ Connecting to CARLA...")
        self.client = carla.Client('localhost', 2000)
        self.client.set_timeout(10.0)
        self.world = self.client.get_world()
        
        # Traffic Manager ì´ˆê¸°í™” (autopilot í•„ìˆ˜!)
        self.traffic_manager = self.client.get_trafficmanager(8000)
        self.traffic_manager.set_synchronous_mode(True)
        
        # ì•ˆì „ ì£¼í–‰ ì„¤ì •
        self.traffic_manager.set_global_distance_to_leading_vehicle(3.0)  # ì•ì°¨ ê±°ë¦¬ ì¦ê°€
        self.traffic_manager.global_percentage_speed_difference(30.0)  # ì†ë„ 30% ê°ì†Œ (ì•ˆì „ ì£¼í–‰)
        
        # ë™ê¸° ëª¨ë“œ ì„¤ì • (ì¤‘ìš”!)
        settings = self.world.get_settings()
        settings.synchronous_mode = True
        settings.fixed_delta_seconds = 0.05  # 20 FPS simulation
        self.world.apply_settings(settings)
        
        print("âœ… Connected to CARLA")
        
        # ë°ì´í„° ì €ì¥ìš©
        self.image_queue = Queue()
        self.frame_count = 0
        self.data_records = []
        
        # ì°¨ëŸ‰, ì¹´ë©”ë¼
        self.vehicle = None
        self.camera = None
    
    def spawn_vehicle(self):
        """ì°¨ëŸ‰ ìƒì„±"""
        print("\nğŸš— Spawning vehicle...")
        
        # ì°¨ëŸ‰ blueprint
        bp_lib = self.world.get_blueprint_library()
        vehicle_bp = bp_lib.filter('vehicle.tesla.model3')[0]
        
        # ìŠ¤í° í¬ì¸íŠ¸
        spawn_points = self.world.get_map().get_spawn_points()
        spawn_point = np.random.choice(spawn_points)
        
        # ì°¨ëŸ‰ ìƒì„±
        self.vehicle = self.world.spawn_actor(vehicle_bp, spawn_point)
        
        print(f"âœ… Vehicle spawned at {spawn_point.location}")
        return self.vehicle
    
    def spawn_camera(self):
        """ì¹´ë©”ë¼ ìƒì„± (ì°¨ëŸ‰ì— ë¶€ì°©)"""
        print("ğŸ“· Spawning camera...")
        
        bp_lib = self.world.get_blueprint_library()
        camera_bp = bp_lib.find('sensor.camera.rgb')
        
        # ì¹´ë©”ë¼ ì„¤ì •
        camera_bp.set_attribute('image_size_x', '640')
        camera_bp.set_attribute('image_size_y', '480')
        camera_bp.set_attribute('fov', '90')
        
        # ì°¨ëŸ‰ ì•ìª½ ìœ„ì— ë¶€ì°©
        camera_transform = carla.Transform(
            carla.Location(x=1.5, z=2.4)
        )
        
        self.camera = self.world.spawn_actor(
            camera_bp, 
            camera_transform, 
            attach_to=self.vehicle
        )
        
        # ì´ë¯¸ì§€ ì½œë°± ë“±ë¡
        self.camera.listen(self.image_queue.put)
        
        print("âœ… Camera attached")
        return self.camera
    
    def get_bounding_boxes(self):
        """ì£¼ë³€ ì°¨ëŸ‰ì˜ bounding box ì¶”ì¶œ"""
        bboxes = []
        
        # ì¹´ë©”ë¼ ìœ„ì¹˜
        camera_transform = self.camera.get_transform()
        
        # ì£¼ë³€ ì°¨ëŸ‰ ì°¾ê¸°
        vehicles = self.world.get_actors().filter('vehicle.*')
        
        for vehicle in vehicles:
            if vehicle.id == self.vehicle.id:
                continue  # ìê¸° ìì‹  ì œì™¸
            
            # ê±°ë¦¬ ì²´í¬ (ë„ˆë¬´ ë¨¼ ì°¨ëŸ‰ ì œì™¸)
            distance = vehicle.get_location().distance(
                self.vehicle.get_location()
            )
            if distance > 50.0:  # 50m ì´ë‚´ë§Œ
                continue
            
            # Bounding box ì¢Œí‘œ ê³„ì‚°
            bbox = self.get_image_bbox(vehicle, camera_transform)
            
            if bbox is not None:
                bboxes.append({
                    'class': 0,  # vehicle
                    'bbox': bbox
                })
        
        return bboxes
    
    def get_image_bbox(self, actor, camera_transform):
        """3D bboxë¥¼ 2D ì´ë¯¸ì§€ ì¢Œí‘œë¡œ íˆ¬ì˜"""
        # Bounding box ê¼­ì§“ì 
        bbox = actor.bounding_box
        vertices = bbox.get_world_vertices(actor.get_transform())
        
        # ì¹´ë©”ë¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        K = self.build_projection_matrix(640, 480, 90)
        
        # 2D íˆ¬ì˜
        points_2d = []
        for vertex in vertices:
            # World to camera
            point_camera = self.world_to_camera(vertex, camera_transform)
            
            # ì¹´ë©”ë¼ ë’¤ì— ìˆìœ¼ë©´ ì œì™¸
            if point_camera[2] < 0:
                return None
            
            # Camera to image
            point_2d = self.camera_to_image(point_camera, K)
            points_2d.append(point_2d)
        
        # Bounding box (min/max)
        points_2d = np.array(points_2d)
        x_min, y_min = points_2d.min(axis=0)
        x_max, y_max = points_2d.max(axis=0)
        
        # ì´ë¯¸ì§€ ë°–ì´ë©´ ì œì™¸
        if x_max < 0 or x_min > 640 or y_max < 0 or y_min > 480:
            return None
        
        # Clip to image bounds
        x_min = max(0, x_min)
        y_min = max(0, y_min)
        x_max = min(640, x_max)
        y_max = min(480, y_max)
        
        # YOLO format: x_center, y_center, width, height (normalized)
        x_center = (x_min + x_max) / 2.0 / 640
        y_center = (y_min + y_max) / 2.0 / 480
        width = (x_max - x_min) / 640
        height = (y_max - y_min) / 480
        
        return [x_center, y_center, width, height]
    
    def world_to_camera(self, point, camera_transform):
        """World ì¢Œí‘œë¥¼ Camera ì¢Œí‘œë¡œ ë³€í™˜"""
        # Camera matrix (world to camera)
        world_2_camera = np.array(camera_transform.get_inverse_matrix())
        
        # Point to homogeneous
        point_homo = [point.x, point.y, point.z, 1]
        
        # Transform
        point_camera = world_2_camera.dot(point_homo)
        
        # Change from UE4's coordinate system to camera
        # (x, y, z) -> (y, -z, x)
        return [point_camera[1], -point_camera[2], point_camera[0]]
    
    def camera_to_image(self, point, K):
        """Camera ì¢Œí‘œë¥¼ Image ì¢Œí‘œë¡œ íˆ¬ì˜"""
        # Perspective projection
        x = K[0, 0] * point[0] / point[2] + K[0, 2]
        y = K[1, 1] * point[1] / point[2] + K[1, 2]
        return [x, y]
    
    def build_projection_matrix(self, w, h, fov):
        """Intrinsic matrix"""
        focal = w / (2.0 * np.tan(fov * np.pi / 360.0))
        K = np.identity(3)
        K[0, 0] = K[1, 1] = focal
        K[0, 2] = w / 2.0
        K[1, 2] = h / 2.0
        return K
    
    def save_frame(self, image_data, control, velocity):
        """í”„ë ˆì„ ì €ì¥"""
        # ì´ë¯¸ì§€ ë³€í™˜
        array = np.frombuffer(image_data.raw_data, dtype=np.uint8)
        array = array.reshape((480, 640, 4))[:, :, :3]  # BGRA -> BGR
        
        # íŒŒì¼ëª…
        filename = f'{self.frame_count:06d}'
        
        # ì´ë¯¸ì§€ ì €ì¥
        image_path = self.image_dir / f'{filename}.jpg'
        cv2.imwrite(str(image_path), array)
        
        # Bounding boxes ì €ì¥ (YOLO format)
        bboxes = self.get_bounding_boxes()
        if bboxes:
            label_path = self.label_dir / f'{filename}.txt'
            with open(label_path, 'w') as f:
                for bbox_data in bboxes:
                    cls = bbox_data['class']
                    bbox = bbox_data['bbox']
                    f.write(f"{cls} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\n")
        
        # CSV ë°ì´í„° ì €ì¥
        self.data_records.append({
            'frame': self.frame_count,
            'image': f'{filename}.jpg',
            'steering': control.steer,
            'throttle': control.throttle,
            'brake': control.brake,
            'velocity': velocity,
            'num_objects': len(bboxes),
            'timestamp': time.time()
        })
        
        self.frame_count += 1
    
    def collect(self, duration_minutes=10):
        """
        ë°ì´í„° ìˆ˜ì§‘ ë©”ì¸ ë£¨í”„
        
        Args:
            duration_minutes: ìˆ˜ì§‘ ì‹œê°„ (ë¶„)
        """
        print(f"\nğŸ“Š Starting data collection for {duration_minutes} minutes...")
        print(f"   Target FPS: {self.fps}")
        print(f"   Expected frames: ~{int(duration_minutes * 60 * self.fps)}")
        print(f"   Output: {self.output_dir}/")
        print("\nâ±ï¸  Press Ctrl+C to stop early\n")
        
        # ì°¨ëŸ‰ ìƒì„±
        self.spawn_vehicle()
        self.spawn_camera()
        
        # Autopilot í™œì„±í™” (Traffic Manager ì‚¬ìš©)
        self.vehicle.set_autopilot(True, self.traffic_manager.get_port())
        print("ğŸ¤– Autopilot enabled with Traffic Manager\n")
        
        # ìˆ˜ì§‘ ì‹œì‘
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        last_save_time = 0
        
        try:
            while time.time() < end_time:
                # CARLA tick
                self.world.tick()
                
                # ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
                try:
                    image_data = self.image_queue.get(timeout=1.0)
                except Empty:
                    continue
                
                # FPS ì œì–´ (ì§€ì •ëœ ê°„ê²©ë§ˆë‹¤ë§Œ ì €ì¥)
                current_time = time.time()
                if current_time - last_save_time < self.frame_interval:
                    continue
                
                last_save_time = current_time
                
                # ì°¨ëŸ‰ ì •ë³´ (actor ìœ íš¨ì„± ì²´í¬)
                try:
                    control = self.vehicle.get_control()
                    velocity_vec = self.vehicle.get_velocity()
                    velocity = np.linalg.norm([velocity_vec.x, velocity_vec.y, velocity_vec.z])
                except RuntimeError:
                    # Actorê°€ íŒŒê´´ë¨ (ì¶©ëŒ ë“±) - ì¬ìƒì„±
                    print("\nâš ï¸  Vehicle destroyed, respawning...")
                    self.spawn_vehicle()
                    self.spawn_camera()
                    self.vehicle.set_autopilot(True, self.traffic_manager.get_port())
                    print("âœ… Vehicle respawned, continuing collection\n")
                    continue
                
                # í”„ë ˆì„ ì €ì¥
                self.save_frame(image_data, control, velocity)
                
                # ì§„í–‰ìƒí™© ì¶œë ¥
                elapsed = current_time - start_time
                remaining = end_time - current_time
                fps_actual = self.frame_count / elapsed if elapsed > 0 else 0
                
                print(f"\r[{self.frame_count:5d} frames] "
                      f"Elapsed: {elapsed/60:.1f}m | "
                      f"Remaining: {remaining/60:.1f}m | "
                      f"FPS: {fps_actual:.1f} | "
                      f"Steering: {control.steer:+.3f} | "
                      f"Speed: {velocity*3.6:.1f} km/h", 
                      end='', flush=True)
        
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸  Stopped by user")
        
        finally:
            print("\n\nğŸ’¾ Saving metadata...")
            self.cleanup()
    
    def cleanup(self):
        """ì •ë¦¬ ë° ì €ì¥"""
        # CSV ì €ì¥
        if self.data_records:
            df = pd.DataFrame(self.data_records)
            csv_path = self.output_dir / 'labels.csv'
            df.to_csv(csv_path, index=False)
            print(f"âœ… Saved {len(df)} records to {csv_path}")
        
        # í†µê³„ ì €ì¥
        stats = {
            'total_frames': self.frame_count,
            'duration_seconds': time.time() - self.data_records[0]['timestamp'] if self.data_records else 0,
            'fps_average': len(self.data_records) / (time.time() - self.data_records[0]['timestamp']) if self.data_records else 0,
            'output_dir': str(self.output_dir),
            'collection_date': datetime.now().isoformat()
        }
        
        stats_path = self.output_dir / 'stats.json'
        with open(stats_path, 'w') as f:
            json.dump(stats, f, indent=2)
        print(f"âœ… Saved statistics to {stats_path}")
        
        # ì¹´ë©”ë¼ listening ì¤‘ë‹¨ (ì¤‘ìš”!)
        try:
            if self.camera is not None and self.camera.is_listening:
                self.camera.stop()
        except Exception:
            pass
        
        # ë™ê¸° ëª¨ë“œ í•´ì œ
        try:
            settings = self.world.get_settings()
            settings.synchronous_mode = False
            self.world.apply_settings(settings)
        except Exception:
            pass
        
        # ì•¡í„° ì‚­ì œëŠ” CARLAê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬
        # (ëª…ì‹œì  destroy() í˜¸ì¶œ ì‹œ C++ ì—ëŸ¬ ë°œìƒ)
        
        print("\n" + "="*80)
        print("âœ… Data collection complete!")
        print("="*80)
        print(f"\nğŸ“ Output directory: {self.output_dir}/")
        print(f"   - images/: {self.frame_count} images")
        print(f"   - labels/: {len(list(self.label_dir.glob('*.txt')))} YOLO labels")
        print(f"   - labels.csv: E2E training data")
        print(f"   - stats.json: Collection statistics")
        print("\nğŸ’¡ Next steps:")
        print(f"   1. Check data quality:")
        print(f"      python check_data.py --data {self.output_dir}")
        print(f"   2. Split for training:")
        print(f"      python split_data.py --data {self.output_dir}")
        print()


def main():
    parser = argparse.ArgumentParser(
        description='CARLA ìë™ ë°ì´í„° ìˆ˜ì§‘',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # 10ë¶„ ë™ì•ˆ ìˆ˜ì§‘ (ê¸°ë³¸)
  python auto_collect.py --duration 10
  
  # 30ë¶„ ë™ì•ˆ, ì´ˆë‹¹ 20í”„ë ˆì„ìœ¼ë¡œ ìˆ˜ì§‘
  python auto_collect.py --duration 30 --fps 20
  
  # ì»¤ìŠ¤í…€ ì¶œë ¥ í´ë”
  python auto_collect.py --duration 5 --output my_data
        """
    )
    
    parser.add_argument(
        '--duration',
        type=int,
        default=10,
        help='ìˆ˜ì§‘ ì‹œê°„ (ë¶„) [ê¸°ë³¸: 10]'
    )
    
    parser.add_argument(
        '--fps',
        type=int,
        default=10,
        help='ì´ˆë‹¹ ì €ì¥ í”„ë ˆì„ ìˆ˜ [ê¸°ë³¸: 10]'
    )
    
    parser.add_argument(
        '--output',
        type=str,
        default='collected_data',
        help='ì¶œë ¥ í´ë” [ê¸°ë³¸: collected_data]'
    )
    
    args = parser.parse_args()
    
    print("="*80)
    print("ğŸš— CARLA Auto Data Collector")
    print("="*80)
    print(f"Duration: {args.duration} minutes")
    print(f"FPS: {args.fps}")
    print(f"Output: {args.output}/")
    print("="*80)
    
    # ìˆ˜ì§‘ ì‹œì‘
    collector = CARLADataCollector(
        output_dir=args.output,
        fps=args.fps
    )
    
    collector.collect(duration_minutes=args.duration)


if __name__ == '__main__':
    main()
