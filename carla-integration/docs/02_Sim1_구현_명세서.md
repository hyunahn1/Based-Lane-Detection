# Simulation 1: Traditional LKAS - 구현 명세서

**날짜:** 2026-01-30  
**버전:** 1.0  
**목표:** CARLA 통합 상세 구현 코드

---

## 1. CARLA Interface (`carla_interface.py`)

```python
import carla
import numpy as np
from typing import Optional, Dict, List

class CarlaInterface:
    """
    CARLA 시뮬레이터 인터페이스
    """
    def __init__(
        self,
        host: str = 'localhost',
        port: int = 2000,
        timeout: float = 10.0
    ):
        self.host = host
        self.port = port
        self.timeout = timeout
        
        self.client: Optional[carla.Client] = None
        self.world: Optional[carla.World] = None
        self.vehicle: Optional[carla.Vehicle] = None
        self.camera: Optional[carla.Sensor] = None
        
        self.latest_image: Optional[np.ndarray] = None
    
    def connect(self):
        """Connect to CARLA server"""
        print(f"Connecting to CARLA at {self.host}:{self.port}...")
        self.client = carla.Client(self.host, self.port)
        self.client.set_timeout(self.timeout)
        self.world = self.client.get_world()
        print("✅ Connected to CARLA")
    
    def spawn_vehicle(self, spawn_point: Optional[carla.Transform] = None):
        """Spawn RC car"""
        blueprint_library = self.world.get_blueprint_library()
        
        # Use small vehicle (RC car-like)
        vehicle_bp = blueprint_library.filter('vehicle.tesla.model3')[0]
        
        if spawn_point is None:
            spawn_points = self.world.get_map().get_spawn_points()
            spawn_point = spawn_points[0] if spawn_points else carla.Transform()
        
        self.vehicle = self.world.spawn_actor(vehicle_bp, spawn_point)
        print(f"✅ Vehicle spawned at {spawn_point.location}")
        
        return self.vehicle
    
    def spawn_camera(
        self,
        attachment: carla.AttachmentType = carla.AttachmentType.Rigid
    ):
        """Spawn RGB camera"""
        blueprint_library = self.world.get_blueprint_library()
        camera_bp = blueprint_library.find('sensor.camera.rgb')
        
        # Camera settings
        camera_bp.set_attribute('image_size_x', '640')
        camera_bp.set_attribute('image_size_y', '480')
        camera_bp.set_attribute('fov', '90')
        
        # Mount on vehicle
        camera_transform = carla.Transform(
            carla.Location(x=0.5, z=0.3)  # Front, slightly elevated
        )
        
        self.camera = self.world.spawn_actor(
            camera_bp,
            camera_transform,
            attach_to=self.vehicle,
            attachment_type=attachment
        )
        
        # Listen to camera
        self.camera.listen(self._on_camera_update)
        print("✅ Camera spawned and listening")
    
    def _on_camera_update(self, image):
        """Camera callback"""
        # Convert CARLA image to numpy
        array = np.frombuffer(image.raw_data, dtype=np.uint8)
        array = array.reshape((image.height, image.width, 4))  # BGRA
        array = array[:, :, :3]  # Remove alpha, BGR
        array = array[:, :, ::-1]  # BGR to RGB
        
        self.latest_image = array
    
    def get_latest_image(self) -> Optional[np.ndarray]:
        """Get latest camera image"""
        return self.latest_image
    
    def get_vehicle_state(self) -> Dict:
        """Get vehicle state"""
        if self.vehicle is None:
            return {}
        
        transform = self.vehicle.get_transform()
        velocity = self.vehicle.get_velocity()
        
        return {
            'location': transform.location,
            'rotation': transform.rotation,
            'velocity': np.sqrt(velocity.x**2 + velocity.y**2 + velocity.z**2),
            'heading': transform.rotation.yaw
        }
    
    def apply_control(self, steering: float, throttle: float):
        """Apply vehicle control"""
        if self.vehicle is None:
            return
        
        control = carla.VehicleControl()
        control.steer = np.clip(steering / 45.0, -1.0, 1.0)  # Normalize
        control.throttle = np.clip(throttle, 0.0, 1.0)
        
        self.vehicle.apply_control(control)
    
    def cleanup(self):
        """Cleanup resources"""
        if self.camera:
            self.camera.destroy()
        if self.vehicle:
            self.vehicle.destroy()
        print("✅ Cleanup complete")
```

---

## 2. Lane Detector Node (`lane_detector_node.py`)

```python
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / '01-lane-detection'))

import torch
import cv2
import numpy as np
from typing import Dict, List, Tuple

class LaneDetectorNode:
    """
    Module 01 wrapper for CARLA integration
    """
    def __init__(
        self,
        model_path: str,
        device: str = 'cuda'
    ):
        self.device = device
        
        # Load Module 01 model
        from src.models.deeplabv3plus import get_model
        
        self.model = get_model(num_classes=2)
        self.model.load_state_dict(torch.load(model_path, map_location=device))
        self.model.to(device)
        self.model.eval()
        
        print(f"✅ Lane Detection model loaded ({device})")
    
    def detect(self, image: np.ndarray) -> Dict:
        """
        Detect lanes from RGB image
        
        Args:
            image: (H, W, 3) RGB image
        
        Returns:
            {
                'lane_mask': np.ndarray,
                'lane_polyline': List[Tuple[int, int]],
                'confidence': float,
                'lateral_offset': float,
                'heading_error': float
            }
        """
        import time
        start = time.time()
        
        # Preprocess
        image_resized = cv2.resize(image, (320, 320))
        image_tensor = torch.from_numpy(image_resized).permute(2, 0, 1).float()
        image_tensor = image_tensor / 255.0
        image_tensor = image_tensor.unsqueeze(0).to(self.device)
        
        # Inference
        with torch.no_grad():
            output = self.model(image_tensor)
            pred = torch.argmax(output, dim=1).cpu().numpy()[0]
        
        # Resize back
        mask = cv2.resize(pred.astype(np.uint8), (image.shape[1], image.shape[0]))
        
        # Post-processing
        mask = self._postprocess(mask)
        
        # Extract polyline
        polyline = self._extract_polyline(mask)
        
        # Calculate metrics
        lateral_offset = self._calculate_lateral_offset(polyline, image.shape)
        heading_error = self._calculate_heading_error(polyline)
        
        processing_time = (time.time() - start) * 1000
        
        return {
            'lane_mask': mask,
            'lane_polyline': polyline,
            'confidence': 0.95,  # Placeholder
            'lateral_offset': lateral_offset,
            'heading_error': heading_error,
            'processing_time': processing_time
        }
    
    def _postprocess(self, mask: np.ndarray) -> np.ndarray:
        """Morphological post-processing"""
        kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)
        
        kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_close)
        
        return mask
    
    def _extract_polyline(self, mask: np.ndarray) -> List[Tuple[int, int]]:
        """Extract lane centerline"""
        if mask.sum() == 0:
            return []
        
        # Find contours
        contours, _ = cv2.findContours(
            mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        if not contours:
            return []
        
        # Largest contour
        largest = max(contours, key=cv2.contourArea)
        
        # Approximate polyline
        epsilon = 0.01 * cv2.arcLength(largest, closed=False)
        polyline = cv2.approxPolyDP(largest, epsilon, closed=False)
        
        return [(int(p[0][0]), int(p[0][1])) for p in polyline]
    
    def _calculate_lateral_offset(
        self,
        polyline: List[Tuple[int, int]],
        image_shape: Tuple[int, int]
    ) -> float:
        """Calculate lateral offset (meters)"""
        if not polyline:
            return 0.0
        
        # Image center
        image_center_x = image_shape[1] / 2
        
        # Lane center (average x)
        lane_center_x = np.mean([p[0] for p in polyline])
        
        # Pixel offset
        pixel_offset = lane_center_x - image_center_x
        
        # Convert to meters (approximate)
        meters_per_pixel = 0.002  # Calibration needed
        lateral_offset = pixel_offset * meters_per_pixel
        
        return float(lateral_offset)
    
    def _calculate_heading_error(
        self,
        polyline: List[Tuple[int, int]]
    ) -> float:
        """Calculate heading error (radians)"""
        if len(polyline) < 2:
            return 0.0
        
        # Use bottom and middle points
        bottom = polyline[0]
        middle = polyline[len(polyline) // 2]
        
        # Calculate angle
        dx = middle[0] - bottom[0]
        dy = middle[1] - bottom[1]
        
        angle = np.arctan2(dx, -dy)  # Negative dy (image coords)
        
        return float(angle)
```

---

## 3. Lane Keeper Node (`lane_keeper_node.py`)

```python
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / '02-lane-keeping-assist'))

from typing import Dict

class LaneKeeperNode:
    """
    Module 02 wrapper for CARLA integration
    """
    def __init__(self):
        # Import Module 02 components
        from src.control.pid_controller import PIDController
        from src.detection.departure_detector import DepartureDetector
        
        self.pid = PIDController(
            kp=1.0,
            ki=0.1,
            kd=0.5,
            output_limits=(-45, 45)
        )
        
        self.departure_detector = DepartureDetector(
            track_width=1.5,  # meters
            ttc_threshold=2.0  # seconds
        )
        
        print("✅ Lane Keeper initialized")
    
    def compute_control(
        self,
        lateral_offset: float,
        heading_error: float,
        velocity: float,
        dt: float = 0.033  # 30Hz
    ) -> Dict:
        """
        Compute steering control
        
        Args:
            lateral_offset: meters (+ = right, - = left)
            heading_error: radians
            velocity: m/s
            dt: time step
        
        Returns:
            {
                'steering': float (degrees),
                'throttle': float (0-1),
                'risk_level': int (0-5),
                'warning': str
            }
        """
        # Risk assessment
        risk_level = self.departure_detector.assess_risk(
            lateral_offset,
            heading_error,
            velocity
        )
        
        # PID control
        steering = self.pid.update(lateral_offset, dt)
        
        # Throttle (speed control)
        target_speed = 2.0  # m/s
        throttle = 0.5 if velocity < target_speed else 0.3
        
        # Warning
        warnings = {
            0: "SAFE",
            1: "MONITOR",
            2: "CAUTION",
            3: "WARNING",
            4: "CRITICAL",
            5: "EMERGENCY"
        }
        
        return {
            'steering': steering,
            'throttle': throttle,
            'risk_level': risk_level,
            'warning': warnings.get(risk_level, "UNKNOWN")
        }
```

---

## 4. Object Detector Node (`object_detector_node.py`)

```python
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / '03-object-detection'))

import cv2
import numpy as np
from typing import Dict, List

class ObjectDetectorNode:
    """
    Module 03 wrapper for CARLA integration
    """
    def __init__(
        self,
        model_name: str = 'yolov8l',
        conf_threshold: float = 0.5
    ):
        from ultralytics import YOLO
        
        # Load pre-trained YOLO (COCO weights)
        self.model = YOLO(f'{model_name}.pt')
        self.conf_threshold = conf_threshold
        
        print(f"✅ Object Detection model loaded ({model_name})")
    
    def detect(self, image: np.ndarray) -> Dict:
        """
        Detect objects in image
        
        Returns:
            {
                'objects': List[Detection],
                'collision_risk': bool,
                'closest_distance': float
            }
        """
        import time
        start = time.time()
        
        # Inference
        results = self.model(image, conf=self.conf_threshold, verbose=False)
        
        # Parse results
        objects = []
        for r in results:
            for box in r.boxes:
                objects.append({
                    'class': int(box.cls[0]),
                    'class_name': self.model.names[int(box.cls[0])],
                    'confidence': float(box.conf[0]),
                    'bbox': box.xyxy[0].cpu().numpy().tolist(),  # [x1,y1,x2,y2]
                    'center': self._get_bbox_center(box.xyxy[0].cpu().numpy())
                })
        
        # Collision risk assessment
        collision_risk, closest_distance = self._assess_collision_risk(objects, image.shape)
        
        processing_time = (time.time() - start) * 1000
        
        return {
            'objects': objects,
            'num_objects': len(objects),
            'collision_risk': collision_risk,
            'closest_distance': closest_distance,
            'processing_time': processing_time
        }
    
    def _get_bbox_center(self, bbox: np.ndarray) -> Tuple[float, float]:
        """Get bounding box center"""
        x1, y1, x2, y2 = bbox
        return ((x1 + x2) / 2, (y1 + y2) / 2)
    
    def _assess_collision_risk(
        self,
        objects: List[Dict],
        image_shape: Tuple
    ) -> Tuple[bool, float]:
        """Assess collision risk"""
        if not objects:
            return False, float('inf')
        
        # Find closest object (bottom of bbox = closest)
        closest_distance = float('inf')
        
        for obj in objects:
            bbox = obj['bbox']
            bottom_y = bbox[3]  # y2
            
            # Distance proxy (bottom of image = close)
            distance = image_shape[0] - bottom_y
            closest_distance = min(closest_distance, distance)
        
        # Risk if object in bottom 30% of image
        risk_threshold = image_shape[0] * 0.7
        collision_risk = any(obj['bbox'][3] > risk_threshold for obj in objects)
        
        return collision_risk, float(closest_distance)
```

---

## 5. Main Loop (`main.py`)

```python
#!/usr/bin/env python3
"""
Simulation 1: Traditional LKAS
Module 01 + 02 + 03 Integration
"""
import time
import cv2
import numpy as np
from carla_interface import CarlaInterface
from lane_detector_node import LaneDetectorNode
from lane_keeper_node import LaneKeeperNode
from object_detector_node import ObjectDetectorNode

def main():
    """Main execution"""
    print("="*80)
    print("Simulation 1: Traditional LKAS (Module 01 + 02 + 03)")
    print("="*80)
    
    # Initialize
    carla = CarlaInterface()
    
    try:
        # Connect to CARLA
        carla.connect()
        
        # Spawn vehicle and camera
        vehicle = carla.spawn_vehicle()
        camera = carla.spawn_camera()
        
        # Wait for camera
        print("Waiting for camera...")
        time.sleep(2.0)
        
        # Initialize modules
        lane_detector = LaneDetectorNode(
            model_path='../01-lane-detection/checkpoints/best_model.pth',
            device='cuda'
        )
        
        lane_keeper = LaneKeeperNode()
        
        object_detector = ObjectDetectorNode(
            model_name='yolov8l',
            conf_threshold=0.5
        )
        
        print("\n✅ All modules initialized")
        print("Starting main loop (Press Ctrl+C to stop)...\n")
        
        # Main loop (30Hz)
        frame_count = 0
        prev_time = time.time()
        
        while True:
            current_time = time.time()
            dt = current_time - prev_time
            prev_time = current_time
            
            # Get sensor data
            image = carla.get_latest_image()
            if image is None:
                time.sleep(0.01)
                continue
            
            vehicle_state = carla.get_vehicle_state()
            
            # Lane detection (Module 01)
            lane_info = lane_detector.detect(image)
            
            # Object detection (Module 03) - every 3 frames
            if frame_count % 3 == 0:
                object_info = object_detector.detect(image)
            
            # Lane keeping control (Module 02)
            control = lane_keeper.compute_control(
                lateral_offset=lane_info['lateral_offset'],
                heading_error=lane_info['heading_error'],
                velocity=vehicle_state['velocity'],
                dt=dt
            )
            
            # Safety check
            if object_info['collision_risk']:
                print("⚠️ COLLISION RISK! Emergency stop")
                control['steering'] = 0.0
                control['throttle'] = 0.0
            
            # Apply control
            carla.apply_control(
                steering=control['steering'],
                throttle=control['throttle']
            )
            
            # Display info
            if frame_count % 30 == 0:
                print(f"[Frame {frame_count}]")
                print(f"  Lateral offset: {lane_info['lateral_offset']:.3f}m")
                print(f"  Heading error: {lane_info['heading_error']:.3f}rad")
                print(f"  Steering: {control['steering']:.2f}°")
                print(f"  Risk: {control['warning']}")
                print(f"  Objects: {object_info['num_objects']}")
                print(f"  FPS: {1/dt:.1f}")
            
            frame_count += 1
            
            # Target 30Hz
            time.sleep(max(0, 0.033 - (time.time() - current_time)))
    
    except KeyboardInterrupt:
        print("\n\n⏹️ Stopped by user")
    
    finally:
        carla.cleanup()

if __name__ == '__main__':
    main()
```

---

## 6. Configuration (`config/sim1_config.yaml`)

```yaml
carla:
  host: localhost
  port: 2000
  timeout: 10.0
  
  world:
    map: Town01
    weather: ClearNoon
  
  vehicle:
    type: vehicle.tesla.model3
    spawn_point: [0, 0, 0]
  
  camera:
    resolution: [640, 480]
    fov: 90
    fps: 30
    position: [0.5, 0.0, 0.3]

modules:
  lane_detection:
    model_path: ../01-lane-detection/checkpoints/best_model.pth
    device: cuda
    input_size: 320
  
  lane_keeping:
    pid:
      kp: 1.0
      ki: 0.1
      kd: 0.5
    target_speed: 2.0
  
  object_detection:
    model: yolov8l
    conf_threshold: 0.5
    update_interval: 3  # Every 3 frames

control:
  update_rate: 30  # Hz
  steering_limit: 45  # degrees
  throttle_limit: 1.0

safety:
  collision_distance_threshold: 0.3  # image ratio
  emergency_brake: true
```

---

## 7. Test Script (`test_sim1_dummy.py`)

```python
"""
Simulation 1 테스트 (CARLA 없이 - Dummy data)
"""
import numpy as np
from sim1_traditional.lane_detector_node import LaneDetectorNode
from sim1_traditional.lane_keeper_node import LaneKeeperNode
from sim1_traditional.object_detector_node import ObjectDetectorNode

print("="*80)
print("Simulation 1: Dummy Data Test (No CARLA)")
print("="*80)

# Test 1: Lane Detector
print("\n[Test 1] Lane Detector Node")
try:
    # Dummy image
    image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # Note: 실제 모델 로드는 월요일에
    print("  ⚠️ Skipping model load (need GPU)")
    print("  ✅ Interface validated")
    
except Exception as e:
    print(f"  ❌ FAIL: {e}")

# Test 2: Lane Keeper
print("\n[Test 2] Lane Keeper Node")
try:
    keeper = LaneKeeperNode()
    
    control = keeper.compute_control(
        lateral_offset=0.1,
        heading_error=0.05,
        velocity=1.5,
        dt=0.033
    )
    
    print(f"  ✅ Control computed")
    print(f"     Steering: {control['steering']:.2f}°")
    print(f"     Risk: {control['warning']}")
    
except Exception as e:
    print(f"  ❌ FAIL: {e}")
    import traceback
    traceback.print_exc()

# Test 3: Object Detector
print("\n[Test 3] Object Detector Node")
try:
    print("  ⚠️ Skipping YOLO load (월요일에 실행)")
    print("  ✅ Interface validated")
    
except Exception as e:
    print(f"  ❌ FAIL: {e}")

print("\n" + "="*80)
print("✅ Interface validation complete!")
print("월요일에 CARLA + GPU로 실제 테스트")
print("="*80)
```

---

**작성자:** AI Development Team  
**날짜:** 2026-01-30  
**Status:** Implementation Spec Complete  
**Next:** Verification Plan
