# Module 03: Object Detection System - ê²€ì¦ì„œ

**ë²„ì „:** 1.0  
**ì‘ì„±ì¼:** 2026-01-30  
**ìƒíƒœ:** ê²€ì¦ ê³„íš  
**ì´ˆì :** ì •í™•ë„ ì¤‘ì‹¬ í‰ê°€

---

## ğŸ“‹ ëª©ì°¨

1. [ê²€ì¦ ì „ëµ](#1-ê²€ì¦-ì „ëµ)
2. [ì„±ëŠ¥ ëª©í‘œ (KPI)](#2-ì„±ëŠ¥-ëª©í‘œ-kpi)
3. [í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤](#3-í…ŒìŠ¤íŠ¸-ì¼€ì´ìŠ¤)
4. [ë²¤ì¹˜ë§ˆí¬](#4-ë²¤ì¹˜ë§ˆí¬)
5. [í†µí•© í…ŒìŠ¤íŠ¸](#5-í†µí•©-í…ŒìŠ¤íŠ¸)
6. [ì„±ëŠ¥ í…ŒìŠ¤íŠ¸](#6-ì„±ëŠ¥-í…ŒìŠ¤íŠ¸)
7. [ì•ˆì „ì„± í…ŒìŠ¤íŠ¸](#7-ì•ˆì „ì„±-í…ŒìŠ¤íŠ¸)
8. [ì‹¤ì°¨ í…ŒìŠ¤íŠ¸](#8-ì‹¤ì°¨-í…ŒìŠ¤íŠ¸)

---

## 1. ê²€ì¦ ì „ëµ

### 1.1 ê²€ì¦ ì›ì¹™

1. **ì •ëŸ‰ì  í‰ê°€ ìš°ì„ **
   - COCO mAP ë©”íŠ¸ë¦­ ì‚¬ìš©
   - í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì¸¡ì •
   - í†µê³„ì  ë¶„ì„

2. **ì •ì„±ì  í‰ê°€ ë³´ì™„**
   - ì‹œê°ì  ê²€ì‚¬
   - ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„
   - ì—£ì§€ ì¼€ì´ìŠ¤ í™•ì¸

3. **ë‹¨ê³„ë³„ ê²€ì¦**
   - Unit Test â†’ Integration Test â†’ System Test
   - ê° ë‹¨ê³„ í†µê³¼ í›„ ë‹¤ìŒ ì§„í–‰

### 1.2 ê²€ì¦ í”„ë¡œì„¸ìŠ¤

```
1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Test)
   â”œâ”€ Preprocessing ê²€ì¦
   â”œâ”€ Postprocessing ê²€ì¦
   â””â”€ API í•¨ìˆ˜ ê²€ì¦

2. í†µí•© í…ŒìŠ¤íŠ¸ (Integration Test)
   â”œâ”€ ì „ì²´ íŒŒì´í”„ë¼ì¸ E2E
   â”œâ”€ Module 01, 02 í†µí•©
   â””â”€ ì‹¤ì‹œê°„ ì„±ëŠ¥

3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (Performance Test)
   â”œâ”€ Test set mAP ì¸¡ì •
   â”œâ”€ Ablation studies
   â””â”€ í´ë˜ìŠ¤ë³„ ë¶„ì„

4. ì•ˆì „ì„± í…ŒìŠ¤íŠ¸ (Safety Test)
   â”œâ”€ Fail-safe ë™ì‘
   â”œâ”€ Edge case ì²˜ë¦¬
   â””â”€ ì¥ì‹œê°„ ì•ˆì •ì„±

5. ì‹¤ì°¨ í…ŒìŠ¤íŠ¸ (Real-world Test)
   â”œâ”€ RC íŠ¸ë™ ì£¼í–‰
   â”œâ”€ ì‹¤ì‹œê°„ ê°ì§€
   â””â”€ ì¶©ëŒ íšŒí”¼
```

---

## 2. ì„±ëŠ¥ ëª©í‘œ (KPI)

### 2.1 ì •ëŸ‰ì  ëª©í‘œ

| ë©”íŠ¸ë¦­ | ëª©í‘œ | ìµœì†Œ ìš”êµ¬ | ì¸¡ì • ë°©ë²• |
|--------|------|----------|-----------|
| **mAP@0.5** | > 0.90 | > 0.85 | COCO metric, test set |
| **mAP@0.5:0.95** | > 0.70 | > 0.65 | COCO metric, test set |
| **Precision** | > 0.92 | > 0.88 | TP / (TP + FP) |
| **Recall** | > 0.88 | > 0.82 | TP / (TP + FN) |
| **F1-Score** | > 0.90 | > 0.85 | Harmonic mean |
| **FPS** | > 30 | > 20 | RTX 5090, 640Ã—640 |
| **Inference Time** | < 33ms | < 50ms | Per frame |

### 2.2 í´ë˜ìŠ¤ë³„ ëª©í‘œ

| Class | mAP@0.5 | Precision | Recall | ì´ìœ  |
|-------|---------|-----------|--------|------|
| **traffic_cone** | > 0.92 | > 0.94 | > 0.90 | ì£¼ìš” ê°ì²´ |
| **obstacle** | > 0.90 | > 0.92 | > 0.88 | ì•ˆì „ ì¤‘ìš” |
| **robot_car** | > 0.88 | > 0.90 | > 0.86 | ì¶©ëŒ ë°©ì§€ |
| **traffic_sign** | > 0.85 | > 0.88 | > 0.84 | ì‘ì€ ê°ì²´ |
| **pedestrian** | > 0.80 | > 0.85 | > 0.80 | ë§¤ìš° ì‘ìŒ |

### 2.3 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

**ë¹„êµ ëŒ€ìƒ:**

| Model | mAP@0.5 | FPS | Parameters | ë¹„ê³  |
|-------|---------|-----|------------|------|
| YOLOv5m | 0.64 | 45 | 21M | Baseline |
| YOLOv8m | 0.68 | 50 | 26M | ì¤‘ê°„ ì„ íƒì§€ |
| **YOLOv8l (Ours)** | **> 0.90** | **30+** | **44M** | **ëª©í‘œ** |
| YOLOv8x | 0.71 | 25 | 68M | ê³¼ë„í•œ í¬ê¸° |

---

## 3. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

### 3.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

#### Test Case 1: ObjectDetector ì´ˆê¸°í™”

```python
def test_detector_initialization():
    """Detector ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    detector = ObjectDetector(
        weights='yolov8l.pt',
        device='cuda',
        conf_thres=0.25
    )
    
    # ê²€ì¦
    assert detector.model is not None
    assert detector.device == 'cuda'
    assert detector.conf_thres == 0.25
    assert len(detector.class_names) == 5
```

#### Test Case 2: ë‹¨ì¼ ê°ì²´ ê°ì§€

```python
def test_single_object_detection():
    """ë‹¨ì¼ ê°ì²´ (ì½˜) ê°ì§€"""
    detector = ObjectDetector()
    
    # ì½˜ ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread('test_images/single_cone.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    result = detector.detect(image)
    
    # ê²€ì¦
    assert result['num_detections'] >= 1
    assert 'traffic_cone' in result['class_names']
    assert all(conf >= 0.25 for conf in result['confidences'])
```

#### Test Case 3: ë‹¤ì¤‘ ê°ì²´ ê°ì§€

```python
def test_multiple_objects_detection():
    """ë‹¤ì¤‘ ê°ì²´ ê°ì§€"""
    detector = ObjectDetector()
    
    # ì—¬ëŸ¬ ê°ì²´ê°€ ìˆëŠ” ì´ë¯¸ì§€
    image = cv2.imread('test_images/multiple_objects.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    result = detector.detect(image)
    
    # ê²€ì¦
    assert result['num_detections'] >= 3
    assert len(result['boxes']) == result['num_detections']
    assert len(result['classes']) == result['num_detections']
    assert len(result['confidences']) == result['num_detections']
```

#### Test Case 4: ë¹ˆ ì´ë¯¸ì§€ (ê°ì²´ ì—†ìŒ)

```python
def test_empty_scene():
    """ê°ì²´ ì—†ëŠ” ë¹ˆ ì¥ë©´"""
    detector = ObjectDetector()
    
    # ë¹ˆ íŠ¸ë™ ì´ë¯¸ì§€
    image = cv2.imread('test_images/empty_track.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    result = detector.detect(image)
    
    # ê²€ì¦
    assert result['num_detections'] == 0
    assert len(result['boxes']) == 0
```

#### Test Case 5: Confidence í•„í„°ë§

```python
def test_confidence_filtering():
    """ë‚®ì€ confidence í•„í„°ë§"""
    detector = ObjectDetector(conf_thres=0.50)  # ë†’ì€ ì„ê³„ê°’
    
    image = cv2.imread('test_images/low_confidence.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    result = detector.detect(image)
    
    # ê²€ì¦: ëª¨ë“  ê°ì§€ê°€ 0.50 ì´ìƒ
    for conf in result['confidences']:
        assert conf >= 0.50
```

#### Test Case 6: NMS ë™ì‘ í™•ì¸

```python
def test_nms_functionality():
    """NMSê°€ ì¤‘ë³µ ë°•ìŠ¤ ì œê±°í•˜ëŠ”ì§€ í™•ì¸"""
    detector = ObjectDetector(iou_thres=0.45)
    
    # ê²¹ì¹˜ëŠ” ê°ì²´ê°€ ë§ì€ ì´ë¯¸ì§€
    image = cv2.imread('test_images/overlapping_objects.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    result = detector.detect(image)
    
    # ê²€ì¦: ë°•ìŠ¤ë“¤ì´ ë„ˆë¬´ ê²¹ì¹˜ì§€ ì•ŠìŒ
    boxes = np.array(result['boxes'])
    
    for i in range(len(boxes)):
        for j in range(i + 1, len(boxes)):
            iou = calculate_iou(boxes[i], boxes[j])
            assert iou < 0.45, f"Boxes {i}, {j} overlap too much (IoU={iou})"
```

### 3.2 í†µí•© í…ŒìŠ¤íŠ¸

#### Test Case 7: ì „ì²´ íŒŒì´í”„ë¼ì¸ E2E

```python
def test_end_to_end_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    detector = ObjectDetector(weights='best.pt')
    
    # Test setì˜ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬
    test_images = list(Path('datasets/images/test').glob('*.jpg'))
    
    total_detections = 0
    total_time = 0
    
    for img_path in test_images:
        image = cv2.imread(str(img_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        result = detector.detect(image)
        
        total_detections += result['num_detections']
        total_time += result['inference_time_ms']
        
        # ê²€ì¦
        assert result['inference_time_ms'] < 50  # 50ms ì´í•˜
    
    avg_time = total_time / len(test_images)
    avg_fps = 1000 / avg_time
    
    print(f"âœ… E2E Test: {len(test_images)} images")
    print(f"   Avg time: {avg_time:.2f} ms")
    print(f"   Avg FPS:  {avg_fps:.1f}")
    print(f"   Total detections: {total_detections}")
    
    assert avg_fps >= 20  # ìµœì†Œ 20 FPS
```

#### Test Case 8: Module 01 í†µí•©

```python
def test_integration_with_module01():
    """Module 01 (Lane Detection)ê³¼ í†µí•©"""
    from module_01 import LaneDetector
    from module_03 import ObjectDetector
    
    lane_detector = LaneDetector()
    object_detector = ObjectDetector()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
    image = cv2.imread('test_images/track_with_objects.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # ì°¨ì„  ê°ì§€
    lane_output = lane_detector.detect(image)
    
    # ê°ì²´ ê°ì§€
    object_output = object_detector.detect(image)
    
    # ê²€ì¦
    assert lane_output['is_valid'] == True
    assert object_output['num_detections'] >= 0
    
    print(f"âœ… Integration Test")
    print(f"   Lane detected:   {lane_output['is_valid']}")
    print(f"   Objects found:   {object_output['num_detections']}")
```

#### Test Case 9: Module 02 í†µí•© (ì¶©ëŒ íšŒí”¼)

```python
def test_integration_with_module02():
    """Module 02 (LKAS)ì™€ í†µí•© - ì¶©ëŒ íšŒí”¼"""
    from module_02 import LaneKeepingAssist
    from module_03 import ObjectDetector
    
    lkas = LaneKeepingAssist()
    detector = ObjectDetector()
    
    # ì¥ì• ë¬¼ì´ ìˆëŠ” ì°¨ì„  ì´ë¯¸ì§€
    image = cv2.imread('test_images/obstacle_in_lane.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # ê°ì²´ ê°ì§€
    detections = detector.detect(image)
    
    # ì°¨ì„  ë‚´ ì¥ì• ë¬¼ ì²´í¬
    has_obstacle = any(
        cls_name in ['obstacle', 'robot_car'] 
        for cls_name in detections['class_names']
    )
    
    # LKAS ë™ì‘ í™•ì¸
    if has_obstacle:
        # ê²½ê³  ë˜ëŠ” íšŒí”¼ ë™ì‘
        assert detections['num_detections'] > 0
        print("âš ï¸ Obstacle detected in lane - LKAS should avoid")
    
    print(f"âœ… LKAS Integration Test")
    print(f"   Obstacle present: {has_obstacle}")
```

---

## 4. ë²¤ì¹˜ë§ˆí¬

### 4.1 ì •í™•ë„ ë²¤ì¹˜ë§ˆí¬

**Test Set í‰ê°€ (150 images)**

**ëª©í‘œ:**

```python
Expected Results:
{
    "mAP@0.5": 0.90,          # Target
    "mAP@0.5:0.95": 0.70,     # Target
    "precision": 0.92,         # Target
    "recall": 0.88,            # Target
    "f1_score": 0.90           # Target
}
```

**í´ë˜ìŠ¤ë³„ ì˜ˆìƒ ì„±ëŠ¥:**

```python
Expected Class Performance:
{
    "traffic_cone": {
        "AP@0.5": 0.92,
        "precision": 0.94,
        "recall": 0.90
    },
    "obstacle": {
        "AP@0.5": 0.90,
        "precision": 0.92,
        "recall": 0.88
    },
    "robot_car": {
        "AP@0.5": 0.88,
        "precision": 0.90,
        "recall": 0.86
    },
    "traffic_sign": {
        "AP@0.5": 0.85,
        "precision": 0.88,
        "recall": 0.84
    },
    "pedestrian": {
        "AP@0.5": 0.80,
        "precision": 0.85,
        "recall": 0.80
    }
}
```

### 4.2 ì†ë„ ë²¤ì¹˜ë§ˆí¬

**ì¶”ë¡  ì‹œê°„ ì¸¡ì • (RTX 5090)**

| ì…ë ¥ í¬ê¸° | YOLOv8m | YOLOv8l (ëª©í‘œ) | YOLOv8x |
|----------|---------|---------------|---------|
| 320Ã—320 | 10ms (100 FPS) | 15ms (67 FPS) | 22ms (45 FPS) |
| **640Ã—640** | **17ms (59 FPS)** | **25ms (40 FPS)** | **35ms (29 FPS)** |
| 1280Ã—1280 | 55ms (18 FPS) | 80ms (13 FPS) | 120ms (8 FPS) |

**ëª©í‘œ:** 640Ã—640ì—ì„œ 25ms (40 FPS) âœ…

### 4.3 ë©”ëª¨ë¦¬ ë²¤ì¹˜ë§ˆí¬

| Model | Parameters | Training Memory | Inference Memory |
|-------|-----------|-----------------|------------------|
| YOLOv8m | 26M | ~8 GB | ~2 GB |
| **YOLOv8l** | **44M** | **~12 GB** | **~3 GB** |
| YOLOv8x | 68M | ~18 GB | ~5 GB |

**ëª©í‘œ:** ì¶”ë¡  ì‹œ < 4GB âœ…

---

## 5. í†µí•© í…ŒìŠ¤íŠ¸

### 5.1 Test Scenario 1: ì •ìƒ ì£¼í–‰

```python
def test_scenario_normal_driving():
    """
    ì‹œë‚˜ë¦¬ì˜¤: ì¥ì• ë¬¼ ì—†ëŠ” ì •ìƒ ì£¼í–‰
    
    Setup:
        - ë¹ˆ íŠ¸ë™ ì´ë¯¸ì§€
        - ì°¨ì„  ëª…í™•
    
    Expected:
        - 0ê°œ ë˜ëŠ” ë§¤ìš° ì ì€ ê°ì§€
        - False Positive ì—†ìŒ
    """
    detector = ObjectDetector()
    image = load_test_image('empty_track.jpg')
    
    result = detector.detect(image)
    
    # ê²€ì¦
    assert result['num_detections'] <= 2  # ìµœëŒ€ 2ê°œ (ë…¸ì´ì¦ˆ)
    print(f"âœ… Normal driving: {result['num_detections']} detections")
```

### 5.2 Test Scenario 2: ì½˜ íšŒí”¼

```python
def test_scenario_cone_avoidance():
    """
    ì‹œë‚˜ë¦¬ì˜¤: íŠ¸ë˜í”½ ì½˜ íšŒí”¼
    
    Setup:
        - íŠ¸ë™ì— 3ê°œ ì½˜ ë°°ì¹˜
        - ê±°ë¦¬: 1m, 2m, 3m
    
    Expected:
        - 3ê°œ ëª¨ë‘ ê°ì§€
        - Confidence > 0.80
    """
    detector = ObjectDetector()
    image = load_test_image('three_cones.jpg')
    
    result = detector.detect(image)
    
    # ê²€ì¦
    cone_detections = [
        i for i, name in enumerate(result['class_names'])
        if name == 'traffic_cone'
    ]
    
    assert len(cone_detections) == 3  # 3ê°œ ê°ì§€
    
    for idx in cone_detections:
        assert result['confidences'][idx] > 0.80
    
    print(f"âœ… Cone avoidance: {len(cone_detections)}/3 detected")
```

### 5.3 Test Scenario 3: ë‹¤ì¤‘ ê°ì²´

```python
def test_scenario_complex_scene():
    """
    ì‹œë‚˜ë¦¬ì˜¤: ë³µì¡í•œ ì¥ë©´
    
    Setup:
        - 5ê°œ ì½˜ + 2ê°œ ì¥ì• ë¬¼ + 1ê°œ RC ì¹´
        - ì¼ë¶€ ê°€ë¦¼ (50%)
    
    Expected:
        - ìµœì†Œ 6ê°œ ê°ì§€ (75% recall)
        - ê° í´ë˜ìŠ¤ ìµœì†Œ 1ê°œ
    """
    detector = ObjectDetector()
    image = load_test_image('complex_scene.jpg')
    
    result = detector.detect(image)
    
    # ê²€ì¦
    assert result['num_detections'] >= 6
    
    detected_classes = set(result['class_names'])
    assert 'traffic_cone' in detected_classes
    assert 'obstacle' in detected_classes
    
    print(f"âœ… Complex scene: {result['num_detections']} objects")
    print(f"   Classes: {detected_classes}")
```

### 5.4 Test Scenario 4: ì¡°ëª… ë³€í™”

```python
def test_scenario_lighting_variations():
    """
    ì‹œë‚˜ë¦¬ì˜¤: ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´
    
    Setup:
        - ë™ì¼ ì¥ë©´, ë‹¤ë¥¸ ì¡°ëª… (ë°ìŒ/ë³´í†µ/ì–´ë‘ì›€)
    
    Expected:
        - ëª¨ë“  ì¡°ëª…ì—ì„œ ê°ì§€
        - mAP variation < 10%
    """
    detector = ObjectDetector()
    
    conditions = ['bright', 'normal', 'dark']
    maps = []
    
    for condition in conditions:
        image = load_test_image(f'lighting_{condition}.jpg')
        result = detector.detect(image)
        
        # GTì™€ ë¹„êµí•˜ì—¬ mAP ê³„ì‚°
        mAP = calculate_map_single_image(result, ground_truth)
        maps.append(mAP)
        
        print(f"  {condition}: mAP = {mAP:.3f}")
    
    # ê²€ì¦: variation < 10%
    mAP_std = np.std(maps)
    assert mAP_std < 0.10
    
    print(f"âœ… Lighting robustness: std = {mAP_std:.3f}")
```

---

## 6. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### 6.1 Test Set í‰ê°€

**ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸:**

```python
# validate.py

def evaluate_test_set():
    """Test set ì „ì²´ í‰ê°€"""
    from ultralytics import YOLO
    
    model = YOLO('runs/train/exp/weights/best.pt')
    
    # Test set í‰ê°€
    metrics = model.val(
        data='config/dataset.yaml',
        split='test',
        imgsz=640,
        batch=16,
        conf=0.25,
        iou=0.45,
        verbose=True
    )
    
    # ê²°ê³¼ ì¶œë ¥
    results = {
        "mAP@0.5": float(metrics.box.map50),
        "mAP@0.5:0.95": float(metrics.box.map),
        "precision": float(metrics.box.p),
        "recall": float(metrics.box.r),
        "f1": float(metrics.box.f1)
    }
    
    print("\n" + "="*60)
    print("ğŸ“Š Test Set Evaluation Results")
    print("="*60)
    
    for metric, value in results.items():
        print(f"{metric:20s}: {value:.4f}")
    
    # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
    passed = (
        results['mAP@0.5'] >= 0.90 and
        results['precision'] >= 0.92 and
        results['recall'] >= 0.88
    )
    
    print(f"\n{'âœ… PASSED' if passed else 'âŒ FAILED'} - Goals met: {passed}")
    
    return results
```

### 6.2 Confusion Matrix

```python
def generate_confusion_matrix():
    """Confusion matrix ìƒì„±"""
    from sklearn.metrics import confusion_matrix
    import seaborn as sns
    
    # Test set predictions vs ground truth
    y_true = []  # Ground truth classes
    y_pred = []  # Predicted classes
    
    # ... predictions ìˆ˜ì§‘ ...
    
    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3, 4])
    
    # ì‹œê°í™”
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', 
                xticklabels=class_names,
                yticklabels=class_names,
                cmap='Blues')
    plt.ylabel('True')
    plt.xlabel('Predicted')
    plt.title('Confusion Matrix - YOLOv8l')
    plt.savefig('results/confusion_matrix.png', dpi=150)
    
    print("âœ… Confusion matrix saved")
```

### 6.3 Precision-Recall Curve

```python
def generate_pr_curve():
    """Precision-Recall curve ìƒì„±"""
    # ê° í´ë˜ìŠ¤ë³„ë¡œ PR curve
    
    for cls_id, cls_name in enumerate(class_names):
        precisions, recalls = calculate_pr_curve(
            predictions, ground_truths, class_id=cls_id
        )
        
        plt.plot(recalls, precisions, label=cls_name)
    
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curves')
    plt.legend()
    plt.grid(True)
    plt.savefig('results/pr_curves.png', dpi=150)
    
    print("âœ… PR curves saved")
```

---

## 7. ì•ˆì „ì„± í…ŒìŠ¤íŠ¸

### 7.1 Fail-safe í…ŒìŠ¤íŠ¸

```python
def test_failsafe_behavior():
    """Fail-safe ë™ì‘ ê²€ì¦"""
    detector = ObjectDetector()
    
    # Test 1: Invalid image
    try:
        invalid_image = np.zeros((10, 10), dtype=np.uint8)  # Wrong shape
        result = detector.detect(invalid_image)
        # Should handle gracefully
        assert 'error' in result or result['num_detections'] == 0
        print("âœ… Invalid image handled")
    except Exception as e:
        print(f"âŒ Failed to handle invalid image: {e}")
        raise
    
    # Test 2: GPU OOM
    try:
        # ë§¤ìš° í° ë°°ì¹˜ (GPU ë©”ëª¨ë¦¬ ì´ˆê³¼)
        large_batch = [np.zeros((640, 640, 3), dtype=np.uint8)] * 100
        results = detector.detect_batch(large_batch)
        # Should fallback to CPU or smaller batches
        print("âœ… GPU OOM handled")
    except Exception as e:
        print(f"âš ï¸ GPU OOM not handled: {e}")
```

### 7.2 Edge Case í…ŒìŠ¤íŠ¸

```python
def test_edge_cases():
    """ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬"""
    detector = ObjectDetector()
    
    edge_cases = [
        'very_small_object.jpg',      # ë§¤ìš° ì‘ì€ ê°ì²´ (2Ã—2 px)
        'very_large_object.jpg',      # í™”ë©´ ê±°ì˜ ë‹¤ ì°¨ì§€
        'extreme_lighting.jpg',       # ê³¼ë„í•œ ë°ê¸°/ì–´ë‘ì›€
        'motion_blur.jpg',            # ëª¨ì…˜ ë¸”ëŸ¬
        'partially_occluded.jpg'      # 80% ê°€ë¦¼
    ]
    
    for case in edge_cases:
        image = load_test_image(case)
        result = detector.detect(image)
        
        # í¬ë˜ì‹œ ì—†ì´ ì‹¤í–‰ë˜ì–´ì•¼ í•¨
        assert 'num_detections' in result
        print(f"âœ… {case}: {result['num_detections']} detections")
```

---

## 8. ì‹¤ì°¨ í…ŒìŠ¤íŠ¸

### 8.1 RC íŠ¸ë™ ì£¼í–‰ í…ŒìŠ¤íŠ¸

**í…ŒìŠ¤íŠ¸ ì ˆì°¨:**

```
1. í•˜ë“œì›¨ì–´ ì…‹ì—…
   - PiRacer ì¤€ë¹„
   - Pi Camera ì—°ê²°
   - RC íŠ¸ë™ ì„¤ì¹˜ (3Ã—4m)

2. ê°ì²´ ë°°ì¹˜
   - 5ê°œ íŠ¸ë˜í”½ ì½˜
   - 2ê°œ ì¥ì• ë¬¼
   - 1ê°œ ë‹¤ë¥¸ RC ì¹´ (ì„ íƒ)

3. ì£¼í–‰ ì‹œë‚˜ë¦¬ì˜¤
   Scenario A: ì§ì„  êµ¬ê°„ íšŒí”¼
   Scenario B: ê³¡ì„  êµ¬ê°„ íšŒí”¼
   Scenario C: ë‹¤ì¤‘ ê°ì²´ íšŒí”¼
   Scenario D: ë™ì  ê°ì²´ (ì›€ì§ì´ëŠ” RC ì¹´)

4. ì¸¡ì • í•­ëª©
   - ì‹¤ì‹œê°„ FPS
   - ê°ì§€ ì •í™•ë„
   - íšŒí”¼ ì„±ê³µë¥ 
   - False Positive ë¹ˆë„
```

### 8.2 ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¸¡ì •

```python
def test_realtime_performance():
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¸¡ì •"""
    import time
    
    detector = ObjectDetector()
    cap = cv2.VideoCapture(0)  # Pi Camera
    
    frame_times = []
    fps_log = []
    
    print("ğŸš— Real-time test started (30 seconds)")
    
    start_time = time.time()
    frame_count = 0
    
    while time.time() - start_time < 30:  # 30ì´ˆ í…ŒìŠ¤íŠ¸
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # ê°ì§€
        t0 = time.time()
        result = detector.detect(frame_rgb)
        t1 = time.time()
        
        frame_time = (t1 - t0) * 1000  # ms
        frame_times.append(frame_time)
        
        # FPS ê³„ì‚°
        if frame_count % 30 == 0:
            fps = 30 / sum(frame_times[-30:]) * 1000
            fps_log.append(fps)
        
        frame_count += 1
    
    cap.release()
    
    # í†µê³„
    avg_time = np.mean(frame_times)
    avg_fps = 1000 / avg_time
    
    print(f"\nğŸ“Š Real-time Performance:")
    print(f"   Avg inference time: {avg_time:.2f} ms")
    print(f"   Avg FPS:            {avg_fps:.1f}")
    print(f"   Min FPS:            {min(fps_log):.1f}")
    print(f"   Max FPS:            {max(fps_log):.1f}")
    
    # ê²€ì¦
    assert avg_fps >= 30, f"FPS too low: {avg_fps:.1f} < 30"
    
    print("âœ… Real-time test PASSED")
```

---

## 9. ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 9.1 êµ¬í˜„ ê²€ì¦

- [ ] ObjectDetector í´ë˜ìŠ¤ êµ¬í˜„
- [ ] YOLOTrainer í´ë˜ìŠ¤ êµ¬í˜„
- [ ] DatasetManager í´ë˜ìŠ¤ êµ¬í˜„
- [ ] MetricsCalculator êµ¬í˜„
- [ ] ëª¨ë“  API í•¨ìˆ˜ ë™ì‘
- [ ] Error handling êµ¬í˜„

### 9.2 ì„±ëŠ¥ ê²€ì¦

- [ ] mAP@0.5 > 0.90
- [ ] mAP@0.5:0.95 > 0.70
- [ ] Precision > 0.92
- [ ] Recall > 0.88
- [ ] FPS > 30
- [ ] Inference time < 33ms

### 9.3 í†µí•© ê²€ì¦

- [ ] Module 01 í†µí•© ì„±ê³µ
- [ ] Module 02 í†µí•© ì„±ê³µ
- [ ] ì¶©ëŒ íšŒí”¼ ë™ì‘ í™•ì¸
- [ ] ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ë™ì‘

### 9.4 ì•ˆì „ì„± ê²€ì¦

- [ ] Fail-safe ë™ì‘ í™•ì¸
- [ ] Edge case ì²˜ë¦¬
- [ ] GPU OOM ì²˜ë¦¬
- [ ] 30ë¶„ ì—°ì† ì•ˆì •ì„±

### 9.5 ì‹¤ì°¨ ê²€ì¦

- [ ] RC íŠ¸ë™ ì£¼í–‰ ì„±ê³µ
- [ ] ì‹¤ì‹œê°„ ê°ì§€ ë™ì‘
- [ ] íšŒí”¼ ì„±ê³µë¥  > 90%
- [ ] False Positive < 5%

---

## 10. ì„±ê³µ ê¸°ì¤€

### 10.1 Phase 2 ì™„ë£Œ ê¸°ì¤€

**í•„ìˆ˜ (Must Have):**
- âœ… ëª¨ë“  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- âœ… mAP@0.5 > 0.90
- âœ… Precision > 0.92
- âœ… í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼

**ê¶Œì¥ (Should Have):**
- âœ… FPS > 30
- âœ… Recall > 0.88
- âœ… ì‹¤ì°¨ í…ŒìŠ¤íŠ¸ ì„±ê³µ

**ì„ íƒ (Nice to Have):**
- âœ… ONNX export
- âœ… TensorRT ìµœì í™”
- âœ… ëª¨ë°”ì¼ ë°°í¬

### 10.2 í’ˆì§ˆ ê¸°ì¤€

**ì½”ë“œ í’ˆì§ˆ:**
- Type hints ì‚¬ìš©
- Docstring ì™„ë¹„
- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ > 80%
- Linting í†µê³¼ (flake8, black)

**ë¬¸ì„œ í’ˆì§ˆ:**
- ëª¨ë“  ë¬¸ì„œ ì™„ì„±
- ì„¤ê³„ vs êµ¬í˜„ ì¼ì¹˜ìœ¨ > 95%
- ì„±ëŠ¥ í‰ê°€ ë¬¸ì„œ ì‘ì„±

---

**ì‘ì„± ì™„ë£Œì¼:** 2026-01-30  
**ê²€ì¦ ì˜ˆì •ì¼:** êµ¬í˜„ ì™„ë£Œ í›„  
**ë‹¤ìŒ ë‹¨ê³„:** ë°ì´í„° ìˆ˜ì§‘ ë° êµ¬í˜„ ì‹œì‘
