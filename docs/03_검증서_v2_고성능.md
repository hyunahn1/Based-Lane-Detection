# RCì¹´ ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ê²€ì¦ì„œ v2.0 (ê³ ì„±ëŠ¥)

## ğŸ¯ ê²€ì¦ ëª©í‘œ

**ì„±ëŠ¥ ê¸°ì¤€**: IoU 0.85+ (ê³ ì„±ëŠ¥ ëª¨ë¸)  
**í™˜ê²½**: RTX 5090  
**ë°ì´í„°**: 199ê°œ (ì¦ê°• í›„ 1,000ê°œ)

---

## 1. ê²€ì¦ ê°œìš”

### 1.1 ê²€ì¦ ë²”ìœ„

| ê²€ì¦ í•­ëª© | ëª©í‘œ | ë°©ë²• |
|-----------|------|------|
| ë°ì´í„° í’ˆì§ˆ | ë¬´ê²°ì„±, ë‹¤ì–‘ì„± | ìë™í™” ìŠ¤í¬ë¦½íŠ¸ |
| ëª¨ë¸ ì„±ëŠ¥ | IoU â‰¥ 0.85 | Test set í‰ê°€ |
| í•™ìŠµ ì•ˆì •ì„± | ìˆ˜ë ´, gradient ì•ˆì • | Tensorboard |
| ì¶”ë¡  ì†ë„ | FPS ì¸¡ì • | Benchmark |
| ì œì–´ ì •í™•ì„± | PID ì•ˆì •ì„± | ì‹œë®¬ë ˆì´ì…˜ |
| ì‹¤ì°¨ ì„±ëŠ¥ | ì™„ì£¼ìœ¨ â‰¥ 90% | ë¬¼ë¦¬ í…ŒìŠ¤íŠ¸ |

### 1.2 ê²€ì¦ í™˜ê²½

**ê°œë°œ í™˜ê²½**:
- GPU: RTX 5090 (24GB VRAM)
- PyTorch 2.0+, MMSegmentation 1.0+
- CUDA 11.8 or 12.1

**í…ŒìŠ¤íŠ¸ í™˜ê²½**:
- ë™ì¼ (ë‚˜ì¤‘ì— ì„ë² ë””ë“œë¡œ ì´ì‹)

---

## 2. ë°ì´í„° ê²€ì¦

### 2.1 ìë™í™” ìŠ¤í¬ë¦½íŠ¸

```python
# tests/test_data_quality.py
import pytest
import json
import cv2
import numpy as np
from pathlib import Path

class TestDataQuality:
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
    
    @pytest.fixture
    def dataset_root(self):
        return Path('dataset_augmented')
    
    def test_file_existence(self, dataset_root):
        """íŒŒì¼ ì¡´ì¬ í™•ì¸"""
        assert (dataset_root / 'train.txt').exists()
        assert (dataset_root / 'val.txt').exists()
        assert (dataset_root / 'test.txt').exists()
        
        # ìƒ˜í”Œ íŒŒì¼ í™•ì¸
        with open(dataset_root / 'train.txt') as f:
            lines = f.readlines()
            assert len(lines) > 0
            
            # ì²« ë²ˆì§¸ ìƒ˜í”Œ í™•ì¸
            img_path, mask_path = lines[0].strip().split()
            assert (dataset_root / img_path).exists()
            assert (dataset_root / mask_path).exists()
    
    def test_image_mask_alignment(self, dataset_root):
        """ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ í¬ê¸° ì¼ì¹˜"""
        with open(dataset_root / 'train.txt') as f:
            for line in f.readlines()[:10]:  # 10ê°œ ìƒ˜í”Œ
                img_path, mask_path = line.strip().split()
                
                img = cv2.imread(str(dataset_root / img_path))
                mask = cv2.imread(str(dataset_root / mask_path), cv2.IMREAD_GRAYSCALE)
                
                assert img is not None, f"Image not found: {img_path}"
                assert mask is not None, f"Mask not found: {mask_path}"
                assert img.shape[:2] == mask.shape, f"Size mismatch: {img.shape} vs {mask.shape}"
    
    def test_mask_values(self, dataset_root):
        """ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„ í™•ì¸"""
        with open(dataset_root / 'train.txt') as f:
            for line in f.readlines()[:10]:
                _, mask_path = line.strip().split()
                mask = cv2.imread(str(dataset_root / mask_path), cv2.IMREAD_GRAYSCALE)
                
                unique_values = np.unique(mask)
                # âœ… 0/1 ë˜ëŠ” 0/255 ëª¨ë‘ í—ˆìš©
                assert set(unique_values).issubset({0, 1}) or set(unique_values).issubset({0, 255}), \
                    f"Invalid mask values: {unique_values} (expected {{0,1}} or {{0,255}})"
    
    def test_train_val_test_split(self, dataset_root):
        """ë°ì´í„° ë¶„í•  ì¤‘ë³µ í™•ì¸"""
        def load_file_list(split):
            with open(dataset_root / f'{split}.txt') as f:
                return set(line.strip().split()[0] for line in f)
        
        train_files = load_file_list('train')
        val_files = load_file_list('val')
        test_files = load_file_list('test')
        
        # ì¤‘ë³µ í™•ì¸
        assert len(train_files & val_files) == 0, "Train-Val overlap"
        assert len(train_files & test_files) == 0, "Train-Test overlap"
        assert len(val_files & test_files) == 0, "Val-Test overlap"
        
        # ë¹„ìœ¨ í™•ì¸ (ì˜¤ì°¨ Â±10%)
        total = len(train_files) + len(val_files) + len(test_files)
        train_ratio = len(train_files) / total
        val_ratio = len(val_files) / total
        test_ratio = len(test_files) / total
        
        assert 0.60 <= train_ratio <= 0.80, f"Train ratio: {train_ratio}"
        assert 0.10 <= val_ratio <= 0.25, f"Val ratio: {val_ratio}"
        assert 0.10 <= test_ratio <= 0.25, f"Test ratio: {test_ratio}"
    
    def test_augmentation_diversity(self, dataset_root):
        """ì¦ê°• ë‹¤ì–‘ì„± í™•ì¸"""
        brightness_values = []
        
        with open(dataset_root / 'train.txt') as f:
            for line in f.readlines()[:50]:
                img_path, _ = line.strip().split()
                img = cv2.imread(str(dataset_root / img_path))
                brightness = img.mean()
                brightness_values.append(brightness)
        
        std = np.std(brightness_values)
        assert std > 10, f"Insufficient brightness diversity: std={std:.2f}"

# ì‹¤í–‰
if __name__ == '__main__':
    pytest.main([__file__, '-v'])
```

### 2.2 ì‹¤í–‰

```bash
# ë°ì´í„° ê²€ì¦ ì‹¤í–‰
pytest tests/test_data_quality.py -v

# ê¸°ëŒ€ ì¶œë ¥:
# âœ… test_file_existence PASSED
# âœ… test_image_mask_alignment PASSED
# âœ… test_mask_values PASSED
# âœ… test_train_val_test_split PASSED
# âœ… test_augmentation_diversity PASSED
```

---

## 3. ëª¨ë¸ ê²€ì¦

### 3.1 í•™ìŠµ ëª¨ë‹ˆí„°ë§

```python
# tests/test_training.py
import torch
import numpy as np
from mmseg.apis import init_model

def test_model_loading():
    """ëª¨ë¸ ë¡œë”© í™•ì¸"""
    model = init_model(
        'configs/deeplabv3plus_r101_lane.py',
        'work_dirs/deeplabv3plus_r101_lane/latest.pth',
        device='cuda:0'
    )
    assert model is not None
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸
    num_params = sum(p.numel() for p in model.parameters())
    print(f"Total parameters: {num_params:,}")
    assert 50_000_000 < num_params < 70_000_000, "Parameter count out of range"

def test_forward_pass():
    """Forward pass í…ŒìŠ¤íŠ¸ (MMSeg ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•)"""
    from mmseg.apis import inference_model
    import numpy as np
    
    model = init_model(
        'configs/deeplabv3plus_r101_lane.py',
        checkpoint=None,  # ì²´í¬í¬ì¸íŠ¸ ì—†ì´ í…ŒìŠ¤íŠ¸
        device='cuda:0'
    )
    model.eval()
    
    # Dummy image (numpy array, RGB)
    dummy_img = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)
    
    with torch.no_grad():
        # âœ… ì˜¬ë°”ë¥¸ MMSeg ì¶”ë¡  ë°©ì‹
        result = inference_model(model, dummy_img)
    
    # ì¶œë ¥ í™•ì¸
    assert hasattr(result, 'pred_sem_seg'), "No pred_sem_seg in result"
    pred = result.pred_sem_seg.data  # torch.Tensor
    
    # Shape í™•ì¸ (H, W) ë˜ëŠ” (1, H, W)
    if pred.ndim == 3:
        pred = pred.squeeze(0)
    assert pred.shape == (640, 480), f"Output shape: {pred.shape}"
    
    # ê°’ ë²”ìœ„ í™•ì¸ (í´ë˜ìŠ¤ ì¸ë±ìŠ¤: 0 ë˜ëŠ” 1)
    unique_values = pred.unique().cpu().numpy()
    assert set(unique_values).issubset({0, 1}), f"Invalid class indices: {unique_values}"

def test_gradient_flow():
    """Gradient flow í™•ì¸"""
    model = init_model('configs/deeplabv3plus_r101_lane.py', device='cuda:0')
    model.train()
    
    x = torch.randn(2, 3, 640, 480).cuda()
    target = torch.randint(0, 2, (2, 640, 480)).cuda()
    
    # Forward
    output = model(x)
    loss = torch.nn.functional.cross_entropy(output['pred_sem_seg'].data, target)
    
    # Backward
    loss.backward()
    
    # Gradient í™•ì¸
    for name, param in model.named_parameters():
        if param.requires_grad:
            assert param.grad is not None, f"No gradient: {name}"
            assert not torch.isnan(param.grad).any(), f"NaN gradient: {name}"
            assert not torch.isinf(param.grad).any(), f"Inf gradient: {name}"
```

### 3.2 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```python
# tests/test_performance.py
import time
import torch
from mmseg.apis import init_model, inference_model
import cv2
import numpy as np

def benchmark_inference_speed(model_path, num_runs=100):
    """ì¶”ë¡  ì†ë„ ì¸¡ì •"""
    model = init_model(
        'configs/deeplabv3plus_r101_lane.py',
        model_path,
        device='cuda:0'
    )
    model.eval()
    
    # Dummy image
    dummy_img = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)
    
    # Warmup
    for _ in range(10):
        _ = inference_model(model, dummy_img)
    
    # Benchmark
    times = []
    with torch.no_grad():
        for _ in range(num_runs):
            start = time.time()
            _ = inference_model(model, dummy_img)
            torch.cuda.synchronize()
            times.append(time.time() - start)
    
    mean_time = np.mean(times) * 1000  # ms
    std_time = np.std(times) * 1000
    fps = 1000 / mean_time
    
    print(f"Inference time: {mean_time:.2f} Â± {std_time:.2f} ms")
    print(f"FPS: {fps:.1f}")
    
    # ê³ ì„±ëŠ¥ ëª¨ë¸ì´ë¯€ë¡œ ì†ë„ ìš”êµ¬ì‚¬í•­ ì™„í™”
    assert mean_time < 200, f"Too slow: {mean_time:.2f}ms"
    
    return mean_time, fps

def benchmark_memory_usage(model_path):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •"""
    model = init_model(
        'configs/deeplabv3plus_r101_lane.py',
        model_path,
        device='cuda:0'
    )
    
    torch.cuda.reset_peak_memory_stats()
    
    dummy_img = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)
    _ = inference_model(model, dummy_img)
    
    peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)  # MB
    print(f"Peak GPU memory: {peak_memory:.2f} MB")
    
    # RTX 5090 (24GB)ì´ë¯€ë¡œ ì—¬ìœ  ìˆìŒ
    assert peak_memory < 8000, f"Memory overflow: {peak_memory:.2f} MB"
    
    return peak_memory
```

### 3.3 ì •í™•ë„ í‰ê°€

```python
# tests/test_accuracy.py
from mmseg.apis import init_model, inference_model
import cv2
import numpy as np
from pathlib import Path
from tqdm import tqdm

def calculate_metrics(pred, gt):
    """
    IoU, Precision, Recall ê³„ì‚°
    
    Parameters:
    -----------
    pred : np.ndarray, (H, W), í´ë˜ìŠ¤ ì¸ë±ìŠ¤ {0, 1}
    gt : np.ndarray, (H, W), í´ë˜ìŠ¤ ì¸ë±ìŠ¤ {0, 1} ë˜ëŠ” {0, 255}
    
    Returns:
    --------
    metrics : dict
    """
    # GT ì •ê·œí™” (0/255 â†’ 0/1)
    if gt.max() > 1:
        gt = (gt > 127).astype(np.uint8)
    
    # Predë„ 0/1ë¡œ ë³´ì¥
    pred = (pred > 0).astype(np.uint8)
    gt = (gt > 0).astype(np.uint8)
    
    # TP, FP, FN, TN ê³„ì‚°
    tp = np.logical_and(pred == 1, gt == 1).sum()
    fp = np.logical_and(pred == 1, gt == 0).sum()
    fn = np.logical_and(pred == 0, gt == 1).sum()
    tn = np.logical_and(pred == 0, gt == 0).sum()
    
    # ë©”íŠ¸ë¦­ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    iou = tp / (tp + fp + fn + 1e-8)
    precision = tp / (tp + fp + 1e-8) if (tp + fp) > 0 else 0.0
    recall = tp / (tp + fn + 1e-8) if (tp + fn) > 0 else 0.0
    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-8)
    f1 = 2 * precision * recall / (precision + recall + 1e-8) if (precision + recall) > 0 else 0.0
    
    return {
        'iou': float(iou),
        'precision': float(precision),
        'recall': float(recall),
        'accuracy': float(accuracy),
        'f1': float(f1)
    }

def evaluate_test_set(model_path, test_data_root):
    """í…ŒìŠ¤íŠ¸ì…‹ ì „ì²´ í‰ê°€"""
    model = init_model(
        'configs/deeplabv3plus_r101_lane.py',
        model_path,
        device='cuda:0'
    )
    
    test_data_root = Path(test_data_root)
    with open(test_data_root / 'test.txt') as f:
        test_files = [line.strip().split() for line in f]
    
    all_metrics = []
    
    for img_rel, mask_rel in tqdm(test_files, desc='Evaluating'):
        img_path = test_data_root / img_rel
        mask_path = test_data_root / mask_rel
        
        # ì¶”ë¡ 
        result = inference_model(model, str(img_path))
        pred = result.pred_sem_seg.data[0].cpu().numpy()
        
        # Ground truth
        gt = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = calculate_metrics(pred, gt)
        all_metrics.append(metrics)
    
    # í‰ê· 
    avg_metrics = {
        key: np.mean([m[key] for m in all_metrics])
        for key in all_metrics[0].keys()
    }
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*50)
    print("Test Set Evaluation Results")
    print("="*50)
    for key, value in avg_metrics.items():
        print(f"{key.upper():12s}: {value:.4f}")
    print("="*50)
    
    # âœ… í˜„ì‹¤ì  ëª©í‘œ ê²€ì¦
    assert avg_metrics['iou'] >= 0.70, f"IoU too low: {avg_metrics['iou']:.4f} (ëª©í‘œ: 0.70+)"
    assert avg_metrics['precision'] >= 0.70, f"Precision too low: {avg_metrics['precision']:.4f}"
    assert avg_metrics['recall'] >= 0.70, f"Recall too low: {avg_metrics['recall']:.4f}"
    
    # âš ï¸ ê²½ê³  ìˆ˜ì¤€ (í¬ë§ì  ëª©í‘œ)
    if avg_metrics['iou'] >= 0.80:
        print("ğŸ‰ Excellent! IoU â‰¥ 0.80 ë‹¬ì„±!")
    elif avg_metrics['iou'] >= 0.75:
        print("âœ… Good! IoU â‰¥ 0.75 ë‹¬ì„± (í˜„ì‹¤ì  ëª©í‘œ)")
    else:
        print("âš ï¸ Warning: IoU < 0.75 (ê°œì„  í•„ìš”)")
    
    print("\nâœ… All metrics passed!")
    
    return avg_metrics

if __name__ == '__main__':
    metrics = evaluate_test_set(
        model_path='work_dirs/deeplabv3plus_r101_lane/best_mIoU_epoch_XXX.pth',
        test_data_root='dataset_augmented'
    )
```

---

## 4. ì‹œê°ì  ê²€ì¦

### 4.1 ì˜ˆì¸¡ ì‹œê°í™”

```python
# tests/visualize_predictions.py
import matplotlib.pyplot as plt
from mmseg.apis import init_model, inference_model
import cv2
import numpy as np
from pathlib import Path

def visualize_predictions(model_path, test_data_root, num_samples=10):
    """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
    model = init_model(
        'configs/deeplabv3plus_r101_lane.py',
        model_path,
        device='cuda:0'
    )
    
    test_data_root = Path(test_data_root)
    with open(test_data_root / 'test.txt') as f:
        test_files = [line.strip().split() for line in f]
    
    # ëœë¤ ìƒ˜í”Œë§
    samples = np.random.choice(len(test_files), num_samples, replace=False)
    
    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))
    
    for idx, sample_idx in enumerate(samples):
        img_rel, mask_rel = test_files[sample_idx]
        img_path = test_data_root / img_rel
        mask_path = test_data_root / mask_rel
        
        # ì›ë³¸ ì´ë¯¸ì§€
        image = cv2.imread(str(img_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Ground truth
        gt_mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
        
        # ì˜ˆì¸¡
        result = inference_model(model, str(img_path))
        pred_mask = result.pred_sem_seg.data[0].cpu().numpy()
        
        # IoU ê³„ì‚°
        iou = calculate_metrics(pred_mask, gt_mask)['iou']
        
        # ì‹œê°í™”
        axes[idx, 0].imshow(image)
        axes[idx, 0].set_title('Original Image')
        axes[idx, 0].axis('off')
        
        axes[idx, 1].imshow(gt_mask, cmap='gray')
        axes[idx, 1].set_title('Ground Truth')
        axes[idx, 1].axis('off')
        
        axes[idx, 2].imshow(pred_mask, cmap='gray')
        axes[idx, 2].set_title(f'Prediction (IoU: {iou:.3f})')
        axes[idx, 2].axis('off')
        
        # Overlay
        overlay = image.copy()
        overlay[pred_mask > 0.5] = [0, 255, 0]
        result_img = cv2.addWeighted(image, 0.6, overlay, 0.4, 0)
        axes[idx, 3].imshow(result_img)
        axes[idx, 3].set_title('Overlay')
        axes[idx, 3].axis('off')
    
    plt.tight_layout()
    plt.savefig('predictions_visualization.png', dpi=150, bbox_inches='tight')
    print("âœ… Saved: predictions_visualization.png")
    plt.close()

if __name__ == '__main__':
    visualize_predictions(
        model_path='work_dirs/deeplabv3plus_r101_lane/best_mIoU_epoch_XXX.pth',
        test_data_root='dataset_augmented',
        num_samples=10
    )
```

### 4.2 ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„

```python
# tests/analyze_failures.py
def find_worst_cases(model_path, test_data_root, top_k=10):
    """ì„±ëŠ¥ì´ ê°€ì¥ ë‚®ì€ ì¼€ì´ìŠ¤ ì°¾ê¸°"""
    model = init_model(
        'configs/deeplabv3plus_r101_lane.py',
        model_path,
        device='cuda:0'
    )
    
    test_data_root = Path(test_data_root)
    with open(test_data_root / 'test.txt') as f:
        test_files = [line.strip().split() for line in f]
    
    results = []
    
    for img_rel, mask_rel in tqdm(test_files):
        img_path = test_data_root / img_rel
        mask_path = test_data_root / mask_rel
        
        result = inference_model(model, str(img_path))
        pred = result.pred_sem_seg.data[0].cpu().numpy()
        gt = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
        
        metrics = calculate_metrics(pred, gt)
        results.append((img_path, mask_path, metrics['iou']))
    
    # IoU ë‚®ì€ ìˆœ ì •ë ¬
    results.sort(key=lambda x: x[2])
    
    print(f"\nğŸ” Top {top_k} Worst Cases:")
    for i, (img_path, mask_path, iou) in enumerate(results[:top_k]):
        print(f"{i+1}. {img_path.name}: IoU={iou:.4f}")
    
    return results[:top_k]
```

---

## 5. ì œì–´ ì‹œìŠ¤í…œ ê²€ì¦

### 5.1 í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

```python
# tests/test_postprocessing.py
from inference.postprocess import postprocess_mask, extract_lane_polylines

def test_postprocessing():
    """í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê²€ì¦"""
    # ê°€ìƒ ë§ˆìŠ¤í¬ ìƒì„±
    mask = np.zeros((480, 640), dtype=np.uint8)
    
    # ë‘ ê°œì˜ ì°¨ì„ 
    cv2.line(mask, (100, 400), (50, 100), 1, 5)
    cv2.line(mask, (540, 400), (590, 100), 1, 5)
    
    # ë…¸ì´ì¦ˆ ì¶”ê°€
    noise_points = np.random.randint(0, [480, 640], size=(20, 2))
    for pt in noise_points:
        cv2.circle(mask, tuple(pt[::-1]), 2, 1, -1)
    
    # í›„ì²˜ë¦¬
    filtered = postprocess_mask(mask, min_area=100)
    
    # ë…¸ì´ì¦ˆ ì œê±° í™•ì¸
    num_components_before = cv2.connectedComponents(mask)[0]
    num_components_after = cv2.connectedComponents(filtered)[0]
    assert num_components_after < num_components_before, "Noise not removed"
    
    # Polyline ì¶”ì¶œ
    polylines = extract_lane_polylines(filtered)
    assert len(polylines) == 2, f"Expected 2 lanes, got {len(polylines)}"
    
    for polyline in polylines:
        assert len(polyline) > 5, "Polyline too short"
    
    print("âœ… Postprocessing test passed")
```

### 5.2 PID ì œì–´ ê²€ì¦

```python
# tests/test_control.py
from control.pid_controller import PIDController

def test_pid_controller():
    """PID ì œì–´ê¸° ë™ì‘ ê²€ì¦"""
    controller = PIDController(kp=0.8, ki=0.1, kd=0.3, dt=0.033)
    
    # ìš°ì¸¡ í¸í–¥
    steering = controller.compute(current_position=250, target_position=320)
    assert steering > 0, "Right turn expected"
    assert -1 <= steering <= 1, f"Steering out of range: {steering}"
    
    # ì¢Œì¸¡ í¸í–¥
    controller.reset()
    steering = controller.compute(current_position=390, target_position=320)
    assert steering < 0, "Left turn expected"
    
    # ì¤‘ì•™ ì •ë ¬
    controller.reset()
    steering = controller.compute(current_position=320, target_position=320)
    assert abs(steering) < 0.1, "Steering should be minimal"
    
    print("âœ… PID controller test passed")

def test_pid_stability():
    """PID ì•ˆì •ì„± (ì‹œê°„ ì‘ë‹µ)"""
    controller = PIDController(kp=0.8, ki=0.1, kd=0.3, dt=0.033)
    
    current_pos = 250.0
    target_pos = 320.0
    
    positions = [current_pos]
    
    for _ in range(100):
        steering = controller.compute(current_pos, target_pos)
        current_pos += steering * 10
        positions.append(current_pos)
    
    final_error = abs(positions[-1] - target_pos)
    max_overshoot = max(positions) - target_pos
    
    assert final_error < 20, f"Convergence failed: error={final_error:.2f}"
    assert max_overshoot < 50, f"Overshoot too large: {max_overshoot:.2f}"
    
    print(f"âœ… PID stability: error={final_error:.2f}, overshoot={max_overshoot:.2f}")
```

---

## 6. í†µí•© í…ŒìŠ¤íŠ¸

### 6.1 End-to-End íŒŒì´í”„ë¼ì¸

```python
# tests/test_e2e.py
def test_end_to_end():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    from inference.predictor import LanePredictor
    from inference.postprocess import postprocess_mask, extract_lane_polylines
    from control.path_planner import PathPlanner
    from control.pid_controller import PIDController
    
    # ì´ˆê¸°í™”
    predictor = LanePredictor(
        config_path='configs/deeplabv3plus_r101_lane.py',
        checkpoint_path='work_dirs/deeplabv3plus_r101_lane/best_mIoU_epoch_XXX.pth',
        use_tta=False
    )
    planner = PathPlanner(image_height=480, image_width=640)
    controller = PIDController()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
    test_img = cv2.imread('dataset_augmented/images/test_sample.jpg')
    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)
    
    # ì¶”ë¡ 
    mask, conf = predictor.predict(test_img)
    assert mask is not None
    assert conf > 0.3, f"Low confidence: {conf:.2f}"
    
    # í›„ì²˜ë¦¬
    filtered_mask = postprocess_mask(mask)
    polylines = extract_lane_polylines(filtered_mask)
    assert len(polylines) > 0, "No lanes detected"
    
    # ê²½ë¡œ ê³„íš
    target_x, target_y, path_conf = planner.compute_target_point(polylines)
    assert target_x is not None
    
    # ì œì–´
    current_x = test_img.shape[1] / 2
    steering = controller.compute(current_x, target_x)
    assert -1 <= steering <= 1
    
    print("âœ… E2E pipeline test passed")
    print(f"   Confidence: {conf:.2f}")
    print(f"   Lanes detected: {len(polylines)}")
    print(f"   Steering: {steering:.3f}")
```

---

## 7. ì‹¤ì°¨ í…ŒìŠ¤íŠ¸ í”„ë¡œí† ì½œ

### 7.1 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

**ì‹œë‚˜ë¦¬ì˜¤ 1: ì§ì„  ì£¼í–‰ (3m)**
```
ëª©í‘œ: ê¸°ë³¸ ì°¨ì„  ì¶”ì¢…
í•©ê²© ê¸°ì¤€: 3/3 ì„±ê³µ
```

**ì‹œë‚˜ë¦¬ì˜¤ 2: ì™„ë§Œí•œ ì»¤ë¸Œ (Râ‰¥1.5m)**
```
ëª©í‘œ: ê³¡ì„  ì°¨ì„  ì¶”ì¢…
í•©ê²© ê¸°ì¤€: 3/3 ì„±ê³µ
```

**ì‹œë‚˜ë¦¬ì˜¤ 3: ê¸‰ì»¤ë¸Œ (Râ‰¥0.5m)**
```
ëª©í‘œ: ê·¹ë‹¨ ìƒí™© ëŒ€ì‘
í•©ê²© ê¸°ì¤€: 2/3 ì„±ê³µ (ì†ë„ ìë™ ê°ì†)
```

**ì‹œë‚˜ë¦¬ì˜¤ 4: ì „ì²´ íŠ¸ë™ ì™„ì£¼**
```
ëª©í‘œ: ì¢…í•© ì„±ëŠ¥ í‰ê°€
í•©ê²© ê¸°ì¤€: 9/10 ì„±ê³µ (90% ì™„ì£¼ìœ¨)
```

### 7.2 í‰ê°€ ì§€í‘œ

| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|-----------|
| ì™„ì£¼ìœ¨ | â‰¥ 90% | 10íšŒ ì‹œë„ ì¤‘ ì„±ê³µ íšŸìˆ˜ |
| ì°¨ì„  ì´íƒˆë¥  | â‰¤ 5% | ë¹„ë””ì˜¤ ë¶„ì„ (í”„ë ˆì„ ê¸°ì¤€) |
| í‰ê·  ì†ë„ | 0.4~0.6 m/s | íƒ€ì´ë¨¸ ì¸¡ì • |
| ì¡°í–¥ ì•ˆì •ì„± | Smooth | ê¸‰ê²©í•œ ë³€í™” ë¹ˆë„ |

### 7.3 ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## ì‹¤ì°¨ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‚¬ì „ ì¤€ë¹„
- [ ] ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (Test IoU â‰¥ 0.85)
- [ ] ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] í•˜ë“œì›¨ì–´ ì—°ê²° í™•ì¸
- [ ] ë¹„ìƒ ì •ì§€ ë²„íŠ¼ ë™ì‘ í™•ì¸
- [ ] ë°°í„°ë¦¬ ì¶©ì „ (â‰¥90%)

### ì§ì„  ì£¼í–‰ (3íšŒ)
- [ ] ì‹œë„ 1: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨
- [ ] ì‹œë„ 2: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨
- [ ] ì‹œë„ 3: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨

### ì™„ë§Œí•œ ì»¤ë¸Œ (3íšŒ)
- [ ] ì‹œë„ 1: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨
- [ ] ì‹œë„ 2: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨
- [ ] ì‹œë„ 3: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨

### ê¸‰ì»¤ë¸Œ (3íšŒ)
- [ ] ì‹œë„ 1: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨
- [ ] ì‹œë„ 2: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨
- [ ] ì‹œë„ 3: â¬œ ì„±ê³µ / â¬œ ì‹¤íŒ¨

### ì „ì²´ ì™„ì£¼ (10íšŒ)
- [ ] ì„±ê³µ íšŸìˆ˜: _____ / 10
- [ ] ì™„ì£¼ìœ¨: _____ %

### Fail-safe í…ŒìŠ¤íŠ¸
- [ ] ì°¨ì„  ê°€ë¦¼ â†’ ì •ì§€ í™•ì¸
- [ ] íŠ¸ë™ ì´íƒˆ â†’ ì •ì§€ í™•ì¸

### ìµœì¢… í‰ê°€
- [ ] ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ í•©ê²©
- [ ] ì™„ì£¼ìœ¨ â‰¥ 90%
```

---

## 8. ì„±ëŠ¥ ëª©í‘œ ìš”ì•½

### 8.1 ì •ëŸ‰ì  ëª©í‘œ (í˜„ì‹¤ì  ì¬ì¡°ì •)

| ë©”íŠ¸ë¦­ | ìµœì†Œ ê¸°ì¤€ | í˜„ì‹¤ì  ëª©í‘œ | í¬ë§ ëª©í‘œ | ì‹¤ì¸¡ | í•©ê²© |
|--------|-----------|-------------|-----------|------|------|
| Test IoU | **â‰¥ 0.70** | 0.75-0.80 | 0.80-0.85 | _____ | â¬œ |
| Precision | **â‰¥ 0.70** | 0.75-0.80 | 0.80+ | _____ | â¬œ |
| Recall | **â‰¥ 0.70** | 0.75-0.80 | 0.80+ | _____ | â¬œ |
| F1-Score | **â‰¥ 0.70** | 0.75-0.80 | 0.80+ | _____ | â¬œ |
| ì¶”ë¡  ì†ë„ | < 200ms | < 100ms | < 50ms | _____ | â¬œ |
| GPU ë©”ëª¨ë¦¬ | < 12GB | < 8GB | < 6GB | _____ | â¬œ |
| ì™„ì£¼ìœ¨ | **â‰¥ 70%** | 80-90% | 90%+ | _____ | â¬œ |

âš ï¸ **ì¤‘ìš”**: 
- ìµœì†Œ ê¸°ì¤€ì„ í†µê³¼í•˜ë©´ **í•©ê²©**
- í˜„ì‹¤ì  ëª©í‘œ ë‹¬ì„±í•˜ë©´ **ìš°ìˆ˜**
- í¬ë§ ëª©í‘œëŠ” best case scenario

### 8.2 ì •ì„±ì  ëª©í‘œ

- [ ] ì§ì„ /ê³¡ì„  ì°¨ì„  ì™„ë²½ ê²€ì¶œ
- [ ] ê²½ê³„ ì„ ëª… (blurryí•˜ì§€ ì•ŠìŒ)
- [ ] ì¡°ëª… ë³€í™” ê°•ê±´
- [ ] ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥
- [ ] ì•ˆì •ì  ì£¼í–‰ ì œì–´

---

## 9. ìµœì¢… ê²€ì¦ ë³´ê³ ì„œ í…œí”Œë¦¿

```markdown
# RCì¹´ ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ìµœì¢… ê²€ì¦ ë³´ê³ ì„œ

## 1. ê²€ì¦ ê°œìš”
- ê²€ì¦ ì¼ì: YYYY-MM-DD
- ê²€ì¦ì: ___________
- ëª¨ë¸: DeepLabV3+ (ResNet101)
- í•™ìŠµ í™˜ê²½: RTX 5090

## 2. ë°ì´í„° ê²€ì¦
- [âœ… / âŒ] ë°ì´í„° ë¬´ê²°ì„±
- [âœ… / âŒ] ì¦ê°• í’ˆì§ˆ
- [âœ… / âŒ] Train/Val/Test ë¶„í• 

## 3. ëª¨ë¸ ì„±ëŠ¥
- Test IoU: ______
- Test Precision: ______
- Test Recall: ______
- Test F1-Score: ______
- ì¶”ë¡  ì†ë„: ______ ms
- GPU ë©”ëª¨ë¦¬: ______ MB

**í•©ê²© ì—¬ë¶€**: [âœ… í•©ê²© / âŒ ë¶ˆí•©ê²©]

## 4. ì œì–´ ì‹œìŠ¤í…œ
- [âœ… / âŒ] í›„ì²˜ë¦¬ ì •í™•ì„±
- [âœ… / âŒ] PID ì•ˆì •ì„±
- [âœ… / âŒ] E2E íŒŒì´í”„ë¼ì¸

## 5. ì‹¤ì°¨ í…ŒìŠ¤íŠ¸
- ì§ì„  ì£¼í–‰: _____ / 3
- ì™„ë§Œí•œ ì»¤ë¸Œ: _____ / 3
- ê¸‰ì»¤ë¸Œ: _____ / 3
- ì „ì²´ ì™„ì£¼ìœ¨: _____ %

**í•©ê²© ì—¬ë¶€**: [âœ… í•©ê²© / âŒ ë¶ˆí•©ê²©]

## 6. ìµœì¢… íŒì •
- [âœ… ë°°í¬ ìŠ¹ì¸ / âš ï¸ ì¡°ê±´ë¶€ ìŠ¹ì¸ / âŒ ì¬ê²€ì¦ í•„ìš”]

**ìŠ¹ì¸ì**: ___________
**ë‚ ì§œ**: YYYY-MM-DD
```

---

**ì‘ì„±ì¼**: 2026-01-29  
**ë²„ì „**: 2.0 (ê³ ì„±ëŠ¥)  
**ë‹¤ìŒ ë‹¨ê³„**: êµ¬í˜„ ì‹œì‘
