# ë°ì´í„°ì…‹ êµì²´ & ì¬í•™ìŠµ ê°€ì´ë“œ

ìƒˆë¡œìš´ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ ì¬í•™ìŠµí•˜ëŠ” ì „ì²´ ê³¼ì •ì…ë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨

1. [ë°ì´í„°ì…‹ êµì²´](#1-ë°ì´í„°ì…‹-êµì²´)
2. [COCO í¬ë§· ë³€í™˜](#2-coco-í¬ë§·-ë³€í™˜)
3. [ë°ì´í„° ë¶„í• ](#3-ë°ì´í„°-ë¶„í• )
4. [í•™ìŠµ ì‹¤í–‰](#4-í•™ìŠµ-ì‹¤í–‰)
5. [í…ŒìŠ¤íŠ¸ í‰ê°€](#5-í…ŒìŠ¤íŠ¸-í‰ê°€)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#6-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## 1. ë°ì´í„°ì…‹ êµì²´

### ğŸ“ í•„ìš”í•œ ë°ì´í„° êµ¬ì¡°

```
training_data/
â”œâ”€â”€ images/              â† ìƒˆ ì´ë¯¸ì§€ë“¤
â”‚   â”œâ”€â”€ frame_0001.png
â”‚   â”œâ”€â”€ frame_0002.png
â”‚   â””â”€â”€ ...
â””â”€â”€ annotations/         â† ìƒˆ ì–´ë…¸í…Œì´ì…˜ë“¤
    â”œâ”€â”€ frame_0001.json  (ì´ë¯¸ì§€ì™€ ì´ë¦„ ë§¤ì¹­)
    â”œâ”€â”€ frame_0002.json
    â””â”€â”€ ...
```

### âš ï¸ ì¤‘ìš” ì‚¬í•­

1. **ì´ë¯¸ì§€ íŒŒì¼ëª… = JSON íŒŒì¼ëª…** (í™•ì¥ìë§Œ ë‹¤ë¦„)
   ```
   frame_0001.png  â†”  frame_0001.json  âœ…
   frame_0001.png  â†”  frame_0002.json  âŒ
   ```

2. **JSON í¬ë§·** (ê¸°ì¡´ê³¼ ë™ì¼í•´ì•¼ í•¨)
   ```json
   {
     "version": "1.0",
     "flags": {},
     "shapes": [
       {
         "label": "lane",
         "points": [[x1, y1], [x2, y2], ...],
         "shape_type": "polyline"
       }
     ],
     "imagePath": "frame_0001.png",
     "imageHeight": 480,
     "imageWidth": 640
   }
   ```

### ğŸ”„ êµì²´ ë°©ë²•

#### ë°©ë²• A: ìë™ ìŠ¤í¬ë¦½íŠ¸ (ê¶Œì¥)

```bash
# 1. ìƒˆ ë°ì´í„°ë¥¼ training_data/ì— ë³µì‚¬
# (ê¸°ì¡´ ë°ì´í„°ëŠ” ìë™ ë°±ì—…ë¨)

# 2. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
./scripts/replace_dataset.sh
```

#### ë°©ë²• B: ìˆ˜ë™ êµì²´

```bash
# 1. ê¸°ì¡´ ë°ì´í„° ë°±ì—…
mv training_data training_data_backup_$(date +%Y%m%d_%H%M%S)

# 2. ìƒˆ ë°ì´í„° ë³µì‚¬
cp -r /path/to/new/data training_data/

# 3. êµ¬ì¡° í™•ì¸
ls -lh training_data/images/ | head
ls -lh training_data/annotations/ | head

# 4. ê°œìˆ˜ í™•ì¸
echo "Images: $(find training_data/images -type f | wc -l)"
echo "Annotations: $(find training_data/annotations -type f | wc -l)"
```

---

## 2. COCO í¬ë§· ë³€í™˜

### ì‹¤í–‰

```bash
cd /home/student/ads-skynet/hyunahn
python training_data/convert_coco.py
```

### ì˜ˆìƒ ì¶œë ¥

```
Processing annotations...
  Found 250 images
  Found 250 annotations
  Matched: 250

âœ… COCO format saved: training_data/annotations_coco.json
ğŸ“Š Statistics:
   Images: 250
   Annotations: 750 (3.0 per image)
   Categories: 1 (lane)
```

### âš ï¸ ì—ëŸ¬ ë°œìƒ ì‹œ

| ì—ëŸ¬ | ì›ì¸ | í•´ê²° |
|------|------|------|
| `Image not found` | íŒŒì¼ëª… ë¶ˆì¼ì¹˜ | ì´ë¯¸ì§€ì™€ JSON ì´ë¦„ í™•ì¸ |
| `Invalid JSON` | JSON í¬ë§· ì˜¤ë¥˜ | JSON êµ¬ì¡° í™•ì¸ |
| `No shapes found` | ë¹ˆ ì–´ë…¸í…Œì´ì…˜ | ì°¨ì„ ì´ í‘œì‹œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ |

---

## 3. ë°ì´í„° ë¶„í• 

### ì‹¤í–‰

```bash
python src/data/split_data.py
```

### ì˜ˆìƒ ì¶œë ¥

```
ğŸ”€ Splitting dataset...
   Total: 250 images
   Train: 175 (70%)
   Val: 37 (15%)
   Test: 38 (15%)

âœ… Splits saved:
   training_data/splits/train.json
   training_data/splits/val.json
   training_data/splits/test.json
```

### ë¶„í•  ë¹„ìœ¨ ë³€ê²½ (ì„ íƒ)

```python
# src/data/split_data.py ìˆ˜ì •

split_coco_dataset(
    coco_json_path='training_data/annotations_coco.json',
    output_dir='training_data/splits',
    train_ratio=0.70,  # â† ì—¬ê¸° ìˆ˜ì •
    val_ratio=0.15,
    test_ratio=0.15,
    random_seed=42
)
```

---

## 4. í•™ìŠµ ì‹¤í–‰

### A. Baseline í•™ìŠµ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)

```bash
# 50 epochs, 320x320
python train_baseline.py
```

**ì˜ˆìƒ ì‹œê°„**: 30~40ë¶„  
**ìš©ë„**: ë°ì´í„°ì…‹ í’ˆì§ˆ ë¹ ë¥¸ í™•ì¸

### B. Optimized í•™ìŠµ (ìµœê³  ì„±ëŠ¥)

```bash
# 100 epochs, 384x384, Mixed Precision
nohup python train_optimized.py > logs/training_$(date +%Y%m%d_%H%M%S).log 2>&1 &
```

**ì˜ˆìƒ ì‹œê°„**: 2~3ì‹œê°„  
**ìš©ë„**: ìµœì¢… ëª¨ë¸ í•™ìŠµ

### í•™ìŠµ ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸
tail -f logs/training_*.log

# í˜„ì¬ Epoch í™•ì¸
tail -50 logs/training_*.log | grep "Epoch"

# Best IoU í™•ì¸
tail -200 logs/training_*.log | grep "Best Val IoU" | tail -1

# í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep train_optimized
```

### í•™ìŠµ ì™„ë£Œ í™•ì¸

```bash
# ì™„ë£Œ ë©”ì‹œì§€ í™•ì¸
tail -50 logs/training_*.log | grep "Training complete"

# Best ëª¨ë¸ í™•ì¸
ls -lht checkpoints/optimized/best*.pth | head -1
```

---

## 5. í…ŒìŠ¤íŠ¸ í‰ê°€

### Baseline í‰ê°€

```bash
python test_model.py \
  --checkpoint checkpoints/baseline/best*.pth
```

### Optimized í‰ê°€

```bash
python test_optimized.py
```

### ê²°ê³¼ í™•ì¸

```bash
# JSON ê²°ê³¼
cat test_results_optimized/test_results.json

# ì‹œê°í™”
ls test_results_optimized/*.png
```

---

## 6. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: COCO ë³€í™˜ ì‹¤íŒ¨

```bash
# ì›ì¸: JSON í¬ë§· ì˜¤ë¥˜
# í•´ê²°: ìƒ˜í”Œ JSON í™•ì¸

python -c "
import json
with open('training_data/annotations/frame_0001.json') as f:
    data = json.load(f)
    print(json.dumps(data, indent=2))
"
```

### ë¬¸ì œ 2: í•™ìŠµ ì¤‘ OOM (Out of Memory)

```bash
# í•´ê²° 1: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
# train_optimized.py ìˆ˜ì •:
'batch_size': 4,  # ì›ë˜ 6 â†’ 4

# í•´ê²° 2: í•´ìƒë„ ê°ì†Œ
'input_size': (320, 320),  # ì›ë˜ (384, 384)
```

### ë¬¸ì œ 3: IoUê°€ ë„ˆë¬´ ë‚®ìŒ (<0.50)

```bash
# ì›ì¸ ê°€ëŠ¥ì„±:
1. ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ
2. ì–´ë…¸í…Œì´ì…˜ ì˜¤ë¥˜
3. ë°ì´í„° ë¶€ì¡±

# ì§„ë‹¨:
python scripts/check_data_quality.py  # (ì•„ë˜ ì°¸ì¡°)
```

### ë¬¸ì œ 4: íŠ¹ì • ìƒ˜í”Œì—ì„œ ê³„ì† ì‹¤íŒ¨

```bash
# ì‹¤íŒ¨ ìƒ˜í”Œ í™•ì¸
python -c "
import json
with open('test_results_optimized/test_results.json') as f:
    data = json.load(f)
    failures = [s for s in data['per_sample'] if s['iou'] < 0.5]
    print('Failure samples:')
    for f in failures:
        print(f'  Sample {f[\"index\"]}: IoU {f[\"iou\"]:.4f}')
"

# í•´ë‹¹ ìƒ˜í”Œ ì´ë¯¸ì§€ í™•ì¸
# training_data/splits/test.jsonì—ì„œ ì¸ë±ìŠ¤ ì°¾ê¸°
```

---

## ğŸ“Š ë°ì´í„° í’ˆì§ˆ ì²´í¬ ìŠ¤í¬ë¦½íŠ¸

<details>
<summary>scripts/check_data_quality.py (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)</summary>

```python
"""
ë°ì´í„° í’ˆì§ˆ ì²´í¬ ìŠ¤í¬ë¦½íŠ¸
"""
import json
from pathlib import Path
from PIL import Image

def check_data_quality():
    img_dir = Path('training_data/images')
    ann_dir = Path('training_data/annotations')
    
    print("ğŸ” ë°ì´í„° í’ˆì§ˆ ì²´í¬\n")
    
    # 1. ê°œìˆ˜ í™•ì¸
    images = list(img_dir.glob('*.png')) + list(img_dir.glob('*.jpg'))
    jsons = list(ann_dir.glob('*.json'))
    
    print(f"ğŸ“ íŒŒì¼ ê°œìˆ˜:")
    print(f"   Images: {len(images)}")
    print(f"   JSONs: {len(jsons)}\n")
    
    # 2. ë§¤ì¹­ í™•ì¸
    img_names = {p.stem for p in images}
    json_names = {p.stem for p in jsons}
    
    missing_json = img_names - json_names
    missing_img = json_names - img_names
    
    if missing_json:
        print(f"âš ï¸  ì–´ë…¸í…Œì´ì…˜ ì—†ëŠ” ì´ë¯¸ì§€: {len(missing_json)}ê°œ")
        for name in list(missing_json)[:5]:
            print(f"   - {name}")
    
    if missing_img:
        print(f"âš ï¸  ì´ë¯¸ì§€ ì—†ëŠ” ì–´ë…¸í…Œì´ì…˜: {len(missing_img)}ê°œ")
        for name in list(missing_img)[:5]:
            print(f"   - {name}")
    
    print()
    
    # 3. ì–´ë…¸í…Œì´ì…˜ í’ˆì§ˆ
    empty_annotations = []
    invalid_jsons = []
    
    for json_path in jsons:
        try:
            with open(json_path) as f:
                data = json.load(f)
            
            if not data.get('shapes'):
                empty_annotations.append(json_path.name)
            elif len(data['shapes']) == 0:
                empty_annotations.append(json_path.name)
        except Exception as e:
            invalid_jsons.append((json_path.name, str(e)))
    
    if empty_annotations:
        print(f"âš ï¸  ë¹ˆ ì–´ë…¸í…Œì´ì…˜: {len(empty_annotations)}ê°œ")
        for name in empty_annotations[:5]:
            print(f"   - {name}")
    
    if invalid_jsons:
        print(f"âŒ ì˜ëª»ëœ JSON: {len(invalid_jsons)}ê°œ")
        for name, error in invalid_jsons[:5]:
            print(f"   - {name}: {error}")
    
    print()
    
    # 4. ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
    sizes = {}
    for img_path in list(images)[:10]:  # ìƒ˜í”Œë§
        img = Image.open(img_path)
        size = f"{img.width}x{img.height}"
        sizes[size] = sizes.get(size, 0) + 1
    
    print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸° (ìƒ˜í”Œ 10ê°œ):")
    for size, count in sizes.items():
        print(f"   {size}: {count}ê°œ")
    
    print("\nâœ… ì²´í¬ ì™„ë£Œ!")

if __name__ == '__main__':
    check_data_quality()
```
</details>

```bash
python scripts/check_data_quality.py
```

---

## ğŸ¯ ë¹ ë¥¸ ì°¸ì¡°

### ì „ì²´ íŒŒì´í”„ë¼ì¸ (í•œ ë²ˆì—)

```bash
# 1. ë°ì´í„° êµì²´
./scripts/replace_dataset.sh

# 2. COCO ë³€í™˜
python training_data/convert_coco.py

# 3. ë°ì´í„° ë¶„í• 
python src/data/split_data.py

# 4. í•™ìŠµ (ë°±ê·¸ë¼ìš´ë“œ)
nohup python train_optimized.py > logs/train_$(date +%Y%m%d_%H%M%S).log 2>&1 &

# 5. ëª¨ë‹ˆí„°ë§
tail -f logs/train_*.log

# 6. ì™„ë£Œ í›„ í…ŒìŠ¤íŠ¸
python test_optimized.py
```

### ì£¼ìš” íŒŒì¼ ê²½ë¡œ

```
training_data/
â”œâ”€â”€ images/                      â† ì›ë³¸ ì´ë¯¸ì§€
â”œâ”€â”€ annotations/                 â† ì›ë³¸ JSON
â”œâ”€â”€ annotations_coco.json        â† COCO ë³€í™˜ ê²°ê³¼
â””â”€â”€ splits/
    â”œâ”€â”€ train.json               â† í•™ìŠµ ì…‹
    â”œâ”€â”€ val.json                 â† ê²€ì¦ ì…‹
    â””â”€â”€ test.json                â† í…ŒìŠ¤íŠ¸ ì…‹

checkpoints/
â”œâ”€â”€ baseline/
â”‚   â””â”€â”€ best_iou*.pth           â† Baseline ëª¨ë¸
â””â”€â”€ optimized/
    â””â”€â”€ best_iou*.pth           â† Optimized ëª¨ë¸

test_results_optimized/
â”œâ”€â”€ test_results.json           â† ìˆ˜ì¹˜ ê²°ê³¼
â”œâ”€â”€ distribution.png            â† ë¶„í¬ ê·¸ë˜í”„
â”œâ”€â”€ boxplot.png                 â† Box plot
â””â”€â”€ per_sample.png              â† ìƒ˜í”Œë³„ ì„±ëŠ¥
```

---

## ğŸ“ ë„ì›€ë§

### ë¬¸ì œê°€ ìƒê¸°ë©´?

1. **ë¡œê·¸ í™•ì¸**: `tail -100 logs/training_*.log`
2. **í”„ë¡œì„¸ìŠ¤ í™•ì¸**: `ps aux | grep python`
3. **GPU ë©”ëª¨ë¦¬**: `nvidia-smi`
4. **ë””ìŠ¤í¬ ê³µê°„**: `df -h`

### ê¸´ê¸‰ ì¤‘ë‹¨

```bash
# í•™ìŠµ ì¤‘ë‹¨
pkill -f train_optimized.py

# í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep python | grep train
```

---

**ì‘ì„±ì¼**: 2026-01-29  
**ë²„ì „**: 1.0
